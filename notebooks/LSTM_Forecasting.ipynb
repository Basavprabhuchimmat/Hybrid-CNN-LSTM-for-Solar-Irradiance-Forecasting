{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "twXeULIVKdoB"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "#CNN Regression model for solar irradiance nowcasting from IR sky images.\n",
        "class SolarCNNRegression(nn.Module):\n",
        "\n",
        "\n",
        "    def __init__(self, input_channels=3, num_classes=1):\n",
        "        super(SolarCNNRegression, self).__init__()\n",
        "\n",
        "        # Feature extraction layers (Convolutional backbone)\n",
        "        self.features = nn.Sequential(\n",
        "            # First conv block\n",
        "            nn.Conv2d(input_channels, 32, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(2, 2),  # 240x320 -> 120x160\n",
        "\n",
        "            # Second conv block\n",
        "            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(2, 2),  # 120x160 -> 60x80\n",
        "\n",
        "            # Third conv block\n",
        "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(2, 2),  # 60x80 -> 30x40\n",
        "\n",
        "            # Fourth conv block\n",
        "            nn.Conv2d(128, 256, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(2, 2),  # 30x40 -> 15x20\n",
        "\n",
        "            # Fifth conv block\n",
        "            nn.Conv2d(256, 512, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(512),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.AdaptiveAvgPool2d((1, 1))  # Global average pooling\n",
        "        )\n",
        "\n",
        "        # Regression head for irradiance prediction\n",
        "        self.regressor = nn.Sequential(\n",
        "            nn.Flatten(),\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(512, 256),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(0.3),\n",
        "            nn.Linear(256, 128),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Linear(128, num_classes)  # Output: solar irradiance value\n",
        "        )\n",
        "\n",
        "        # Initialize weights\n",
        "        self._initialize_weights()\n",
        "\n",
        "    def _initialize_weights(self):\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
        "                if m.bias is not None:\n",
        "                    nn.init.constant_(m.bias, 0)\n",
        "            elif isinstance(m, nn.BatchNorm2d):\n",
        "                nn.init.constant_(m.weight, 1)\n",
        "                nn.init.constant_(m.bias, 0)\n",
        "            elif isinstance(m, nn.Linear):\n",
        "                nn.init.normal_(m.weight, 0, 0.01)\n",
        "                nn.init.constant_(m.bias, 0)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Extract features\n",
        "        features = self.features(x)\n",
        "\n",
        "        # Regression prediction\n",
        "        irradiance = self.regressor(features)\n",
        "\n",
        "        return irradiance\n",
        "\n",
        "#Extract features for LSTM input\n",
        "    def get_features(self, x):\n",
        "\n",
        "        with torch.no_grad():\n",
        "            features = self.features(x)\n",
        "            return features.flatten(1)  # Flatten for sequence input\n",
        "\n",
        "\n",
        "class SolarCNNWithFeatureExtraction(SolarCNNRegression):\n",
        "\n",
        "\n",
        "    def __init__(self, input_channels=3, feature_dim=512):\n",
        "        super().__init__(input_channels, 1)\n",
        "        self.feature_dim = feature_dim\n",
        "\n",
        "        # Feature projection layer for LSTM input\n",
        "        self.feature_projector = nn.Sequential(\n",
        "            nn.Linear(512, feature_dim),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(0.2)\n",
        "        )\n",
        "\n",
        "    def forward(self, x, return_features=False):\n",
        "        # Extract convolutional features\n",
        "        conv_features = self.features(x)\n",
        "        flattened_features = conv_features.flatten(1)\n",
        "\n",
        "        # Get irradiance prediction\n",
        "        irradiance = self.regressor[-3:](\n",
        "            self.regressor[:-3](flattened_features)\n",
        "        )\n",
        "\n",
        "        if return_features:\n",
        "            # Project features for LSTM input\n",
        "            projected_features = self.feature_projector(flattened_features)\n",
        "            return irradiance, projected_features\n",
        "\n",
        "        return irradiance\n",
        "\n",
        "\n",
        "# Legacy model for backward compatibility\n",
        "class SolarCNN(SolarCNNRegression):\n",
        "\n",
        "    pass"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vezLLINDDGRF"
      },
      "source": [
        "LSTM model for solar irradiance forecasting\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RZBPPGL0DFqD"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from scripts.cnn_model import SolarCNNWithFeatureExtraction\n",
        "class SolarLSTMForecasting(nn.Module):\n",
        "    \"\"\"\n",
        "    LSTM model for solar irradiance forecasting following the paper methodology.\n",
        "    Uses bidirectional LSTM with 2 layers and 128 hidden units per direction.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, input_size=1, hidden_size=128, num_layers=2, output_size=4, dropout=0.2):\n",
        "        super(SolarLSTMForecasting, self).__init__()\n",
        "\n",
        "        self.input_size = input_size\n",
        "        self.hidden_size = hidden_size\n",
        "        self.num_layers = num_layers\n",
        "        self.output_size = output_size\n",
        "\n",
        "        # Bidirectional LSTM with 2 layers as specified in paper\n",
        "        self.lstm = nn.LSTM(\n",
        "            input_size=input_size,\n",
        "            hidden_size=hidden_size,\n",
        "            num_layers=num_layers,\n",
        "            bidirectional=True,\n",
        "            batch_first=True,\n",
        "            dropout=dropout if num_layers > 1 else 0\n",
        "        )\n",
        "\n",
        "        # Fully connected layers as specified in paper\n",
        "        # Input size is hidden_size * 2 (bidirectional)\n",
        "        lstm_output_size = hidden_size * 2\n",
        "\n",
        "        self.fc_layers = nn.Sequential(\n",
        "            nn.Linear(lstm_output_size, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(dropout),\n",
        "\n",
        "            nn.Linear(128, 64),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(dropout),\n",
        "\n",
        "            nn.Linear(64, output_size)  # Predict next 4 timestamps\n",
        "        )\n",
        "\n",
        "        self._initialize_weights()\n",
        "\n",
        "    def _initialize_weights(self):\n",
        "        for name, param in self.lstm.named_parameters():\n",
        "            if 'weight_ih' in name:\n",
        "                nn.init.xavier_uniform_(param.data)\n",
        "            elif 'weight_hh' in name:\n",
        "                nn.init.orthogonal_(param.data)\n",
        "            elif 'bias' in name:\n",
        "                param.data.fill_(0)\n",
        "                # Set forget gate bias to 1\n",
        "                n = param.size(0)\n",
        "                start, end = n // 4, n // 2\n",
        "                param.data[start:end].fill_(1.)\n",
        "\n",
        "        for m in self.fc_layers:\n",
        "            if isinstance(m, nn.Linear):\n",
        "                nn.init.xavier_uniform_(m.weight)\n",
        "                nn.init.constant_(m.bias, 0)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x shape: (batch_size, sequence_length, input_size)\n",
        "\n",
        "        # LSTM forward pass\n",
        "        lstm_out, (hidden, cell) = self.lstm(x)\n",
        "\n",
        "        # Take the output from the last time step\n",
        "        # lstm_out shape: (batch_size, sequence_length, hidden_size * 2)\n",
        "        last_output = lstm_out[:, -1, :]  # (batch_size, hidden_size * 2)\n",
        "\n",
        "        # Pass through fully connected layers\n",
        "        forecast = self.fc_layers(last_output)\n",
        "\n",
        "        return forecast\n",
        "\n",
        "\n",
        "class HybridCNNLSTM(nn.Module):\n",
        "    \"\"\"\n",
        "    Hybrid CNN-LSTM model as described in the paper.\n",
        "    CNN extracts features from images, LSTM performs temporal forecasting.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, cnn_model=None, feature_dim=512, sequence_length=20,\n",
        "                 lstm_hidden_size=128, forecast_horizon=4):\n",
        "        super(HybridCNNLSTM, self).__init__()\n",
        "\n",
        "        self.sequence_length = sequence_length\n",
        "        self.forecast_horizon = forecast_horizon\n",
        "\n",
        "        # CNN component for nowcasting (pre-trained or trainable)\n",
        "        if cnn_model is None:\n",
        "            self.cnn = SolarCNNWithFeatureExtraction(feature_dim=feature_dim)\n",
        "        else:\n",
        "            self.cnn = cnn_model\n",
        "\n",
        "        # LSTM component for forecasting\n",
        "        self.lstm = SolarLSTMForecasting(\n",
        "            input_size=1,  # Input is the nowcast irradiance values\n",
        "            hidden_size=lstm_hidden_size,\n",
        "            output_size=forecast_horizon\n",
        "        )\n",
        "\n",
        "        # Freeze CNN if using pre-trained model\n",
        "        self.freeze_cnn = False\n",
        "\n",
        "    def set_cnn_trainable(self, trainable=True):\n",
        "        \"\"\"Control whether CNN parameters are trainable\"\"\"\n",
        "        for param in self.cnn.parameters():\n",
        "            param.requires_grad = trainable\n",
        "        self.freeze_cnn = not trainable\n",
        "\n",
        "    def forward(self, image_sequence):\n",
        "        \"\"\"\n",
        "        Forward pass for the hybrid model\n",
        "\n",
        "        Args:\n",
        "            image_sequence: Tensor of shape (batch_size, sequence_length, channels, height, width)\n",
        "\n",
        "        Returns:\n",
        "            nowcasts: Current irradiance predictions for each image\n",
        "            forecasts: Future irradiance predictions\n",
        "        \"\"\"\n",
        "        batch_size, seq_len, channels, height, width = image_sequence.shape\n",
        "\n",
        "        # Reshape for CNN processing\n",
        "        images_flat = image_sequence.view(-1, channels, height, width)\n",
        "\n",
        "        # CNN nowcasting for each image in sequence\n",
        "        nowcasts = self.cnn(images_flat)  # (batch_size * seq_len, 1)\n",
        "        nowcasts = nowcasts.view(batch_size, seq_len, 1)  # (batch_size, seq_len, 1)\n",
        "\n",
        "        # LSTM forecasting using nowcast sequence\n",
        "        forecasts = self.lstm(nowcasts)  # (batch_size, forecast_horizon)\n",
        "\n",
        "        return nowcasts, forecasts\n",
        "\n",
        "    def predict_from_sequence(self, image_sequence):\n",
        "        \"\"\"Prediction method for inference\"\"\"\n",
        "        self.eval()\n",
        "        with torch.no_grad():\n",
        "            nowcasts, forecasts = self.forward(image_sequence)\n",
        "        return nowcasts, forecasts\n",
        "\n",
        "\n",
        "# Simple LSTM for backward compatibility\n",
        "class SolarLSTM(nn.Module):\n",
        "    \"\"\"Legacy LSTM model - kept for compatibility\"\"\"\n",
        "\n",
        "    def __init__(self, input_size=1, hidden_size=128, output_size=1):\n",
        "        super(SolarLSTM, self).__init__()\n",
        "        self.lstm = nn.LSTM(input_size, hidden_size, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        lstm_out, _ = self.lstm(x)\n",
        "        output = self.fc(lstm_out[:, -1, :])\n",
        "        return output\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NJ-lwEHUCeHC",
        "outputId": "1ba491cc-d64c-4189-b012-0d989fcd41d4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading multi-day time series dataset...\n",
            "Train samples: 435458, Val samples: 108865\n",
            "Using device: cuda\n",
            "Starting LSTM training for 50 epochs...\n",
            "Model parameters: 199,684\n",
            "Sequence length: 20, Forecast horizon: 4\n",
            "\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training LSTM: 100%|██████████| 6805/6805 [00:46<00:00, 145.86it/s, Loss=19221.2031]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 140300.1966\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Validation: 100%|██████████| 1702/1702 [00:09<00:00, 184.16it/s, Val Loss=235380.1094]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Val Loss: 112591.2913, Overall RMSE: 335.44 W/m²\n",
            "RMSE per step: ['335.69', '335.09', '335.67', '335.31']\n",
            "New best model saved! RMSE: 335.44 W/m²\n",
            "\n",
            "Epoch 2/50\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training LSTM: 100%|██████████| 6805/6805 [00:46<00:00, 146.65it/s, Loss=7793.6357]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 89065.1135\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Validation: 100%|██████████| 1702/1702 [00:09<00:00, 183.47it/s, Val Loss=158748.5156]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Val Loss: 68857.8227, Overall RMSE: 262.31 W/m²\n",
            "RMSE per step: ['262.54', '261.99', '262.52', '262.19']\n",
            "New best model saved! RMSE: 262.31 W/m²\n",
            "\n",
            "Epoch 3/50\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training LSTM: 100%|██████████| 6805/6805 [00:46<00:00, 145.26it/s, Loss=98240.7031]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 53219.3258\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Validation: 100%|██████████| 1702/1702 [00:09<00:00, 183.35it/s, Val Loss=103237.7891]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Val Loss: 40720.6898, Overall RMSE: 201.70 W/m²\n",
            "RMSE per step: ['201.91', '201.41', '201.90', '201.61']\n",
            "New best model saved! RMSE: 201.70 W/m²\n",
            "\n",
            "Epoch 4/50\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training LSTM: 100%|██████████| 6805/6805 [00:46<00:00, 145.83it/s, Loss=15365.6279]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 31722.2878\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Validation: 100%|██████████| 1702/1702 [00:09<00:00, 180.61it/s, Val Loss=66847.6797]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Val Loss: 24251.4285, Overall RMSE: 155.65 W/m²\n",
            "RMSE per step: ['155.83', '155.37', '155.83', '155.57']\n",
            "New best model saved! RMSE: 155.65 W/m²\n",
            "\n",
            "Epoch 5/50\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training LSTM: 100%|██████████| 6805/6805 [00:46<00:00, 145.28it/s, Loss=14948.1328]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 18483.6619\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Validation: 100%|██████████| 1702/1702 [00:09<00:00, 183.44it/s, Val Loss=41015.2891]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Val Loss: 13738.1752, Overall RMSE: 117.14 W/m²\n",
            "RMSE per step: ['117.29', '116.88', '117.31', '117.09']\n",
            "New best model saved! RMSE: 117.14 W/m²\n",
            "\n",
            "Epoch 6/50\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training LSTM: 100%|██████████| 6805/6805 [00:46<00:00, 147.26it/s, Loss=19017.3027]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 10170.3007\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Validation: 100%|██████████| 1702/1702 [00:09<00:00, 185.38it/s, Val Loss=23220.6523]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Val Loss: 7275.8075, Overall RMSE: 85.24 W/m²\n",
            "RMSE per step: ['85.34', '85.01', '85.39', '85.24']\n",
            "New best model saved! RMSE: 85.24 W/m²\n",
            "\n",
            "Epoch 7/50\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training LSTM: 100%|██████████| 6805/6805 [00:46<00:00, 145.31it/s, Loss=7332.5283]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 5296.9944\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Validation: 100%|██████████| 1702/1702 [00:09<00:00, 185.60it/s, Val Loss=12201.7773]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Val Loss: 3712.2237, Overall RMSE: 60.89 W/m²\n",
            "RMSE per step: ['60.89', '60.68', '61.02', '60.97']\n",
            "New best model saved! RMSE: 60.89 W/m²\n",
            "\n",
            "Epoch 8/50\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training LSTM: 100%|██████████| 6805/6805 [00:47<00:00, 143.93it/s, Loss=1316.2148]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 2777.0430\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Validation: 100%|██████████| 1702/1702 [00:09<00:00, 180.42it/s, Val Loss=6662.3535]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Val Loss: 2082.4256, Overall RMSE: 45.60 W/m²\n",
            "RMSE per step: ['45.49', '45.45', '45.69', '45.79']\n",
            "New best model saved! RMSE: 45.60 W/m²\n",
            "\n",
            "Epoch 9/50\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training LSTM: 100%|██████████| 6805/6805 [00:47<00:00, 144.66it/s, Loss=23.9017]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 1830.5297\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Validation: 100%|██████████| 1702/1702 [00:09<00:00, 182.29it/s, Val Loss=5129.0713]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Val Loss: 1662.1529, Overall RMSE: 40.74 W/m²\n",
            "RMSE per step: ['40.57', '40.62', '40.81', '40.98']\n",
            "New best model saved! RMSE: 40.74 W/m²\n",
            "\n",
            "Epoch 10/50\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training LSTM: 100%|██████████| 6805/6805 [00:46<00:00, 145.34it/s, Loss=34.3899]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 1658.0153\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Validation: 100%|██████████| 1702/1702 [00:09<00:00, 182.07it/s, Val Loss=4923.3418]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Val Loss: 1603.3567, Overall RMSE: 40.02 W/m²\n",
            "RMSE per step: ['39.83', '39.90', '40.07', '40.26']\n",
            "New best model saved! RMSE: 40.02 W/m²\n",
            "\n",
            "Epoch 11/50\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training LSTM: 100%|██████████| 6805/6805 [00:46<00:00, 145.00it/s, Loss=6670.0586]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 1584.7027\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Validation: 100%|██████████| 1702/1702 [00:09<00:00, 176.39it/s, Val Loss=4444.9307]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Val Loss: 1483.8987, Overall RMSE: 38.50 W/m²\n",
            "RMSE per step: ['38.30', '38.38', '38.55', '38.76']\n",
            "New best model saved! RMSE: 38.50 W/m²\n",
            "\n",
            "Epoch 12/50\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training LSTM: 100%|██████████| 6805/6805 [00:49<00:00, 138.49it/s, Loss=1773.7534]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 1524.0150\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Validation: 100%|██████████| 1702/1702 [00:09<00:00, 176.24it/s, Val Loss=4525.1123]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Val Loss: 1500.1529, Overall RMSE: 38.71 W/m²\n",
            "RMSE per step: ['38.50', '38.60', '38.77', '38.97']\n",
            "\n",
            "Epoch 13/50\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training LSTM: 100%|██████████| 6805/6805 [00:48<00:00, 141.45it/s, Loss=268.3941]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 1518.2557\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Validation: 100%|██████████| 1702/1702 [00:09<00:00, 176.97it/s, Val Loss=4396.0146]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Val Loss: 1461.0065, Overall RMSE: 38.20 W/m²\n",
            "RMSE per step: ['37.99', '38.09', '38.26', '38.46']\n",
            "New best model saved! RMSE: 38.20 W/m²\n",
            "\n",
            "Epoch 14/50\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training LSTM: 100%|██████████| 6805/6805 [00:47<00:00, 144.19it/s, Loss=141.2839]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 1485.5885\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Validation: 100%|██████████| 1702/1702 [00:09<00:00, 179.12it/s, Val Loss=4264.7754]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Val Loss: 1427.1778, Overall RMSE: 37.76 W/m²\n",
            "RMSE per step: ['37.54', '37.65', '37.81', '38.02']\n",
            "New best model saved! RMSE: 37.76 W/m²\n",
            "\n",
            "Epoch 15/50\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training LSTM: 100%|██████████| 6805/6805 [00:46<00:00, 144.95it/s, Loss=1306.7168]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 1429.9805\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Validation: 100%|██████████| 1702/1702 [00:09<00:00, 183.92it/s, Val Loss=4214.3428]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Val Loss: 1413.7266, Overall RMSE: 37.58 W/m²\n",
            "RMSE per step: ['37.35', '37.47', '37.64', '37.85']\n",
            "New best model saved! RMSE: 37.58 W/m²\n",
            "\n",
            "Epoch 16/50\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training LSTM: 100%|██████████| 6805/6805 [00:49<00:00, 137.33it/s, Loss=16.6380]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 1442.4452\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Validation: 100%|██████████| 1702/1702 [00:08<00:00, 192.58it/s, Val Loss=4153.0127]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Val Loss: 1398.6541, Overall RMSE: 37.38 W/m²\n",
            "RMSE per step: ['37.15', '37.27', '37.44', '37.65']\n",
            "New best model saved! RMSE: 37.38 W/m²\n",
            "\n",
            "Epoch 17/50\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training LSTM: 100%|██████████| 6805/6805 [00:49<00:00, 136.49it/s, Loss=57.5732]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 1412.5385\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Validation: 100%|██████████| 1702/1702 [00:08<00:00, 189.99it/s, Val Loss=4262.5371]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Val Loss: 1427.5257, Overall RMSE: 37.76 W/m²\n",
            "RMSE per step: ['37.55', '37.65', '37.81', '38.03']\n",
            "\n",
            "Epoch 18/50\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training LSTM: 100%|██████████| 6805/6805 [00:48<00:00, 139.63it/s, Loss=385.5734]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 1424.9657\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Validation: 100%|██████████| 1702/1702 [00:09<00:00, 187.63it/s, Val Loss=4042.5083]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Val Loss: 1368.7519, Overall RMSE: 36.98 W/m²\n",
            "RMSE per step: ['36.76', '36.87', '37.03', '37.24']\n",
            "New best model saved! RMSE: 36.98 W/m²\n",
            "\n",
            "Epoch 19/50\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training LSTM: 100%|██████████| 6805/6805 [00:48<00:00, 140.97it/s, Loss=36.8768]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 1367.3648\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Validation: 100%|██████████| 1702/1702 [00:09<00:00, 178.87it/s, Val Loss=3901.7190]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Val Loss: 1329.6673, Overall RMSE: 36.44 W/m²\n",
            "RMSE per step: ['36.22', '36.33', '36.50', '36.72']\n",
            "New best model saved! RMSE: 36.44 W/m²\n",
            "\n",
            "Epoch 20/50\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training LSTM: 100%|██████████| 6805/6805 [00:47<00:00, 143.61it/s, Loss=2966.6897]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 1336.8199\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Validation: 100%|██████████| 1702/1702 [00:09<00:00, 181.23it/s, Val Loss=3891.3225]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Val Loss: 1328.4762, Overall RMSE: 36.43 W/m²\n",
            "RMSE per step: ['36.20', '36.31', '36.49', '36.71']\n",
            "New best model saved! RMSE: 36.43 W/m²\n",
            "\n",
            "Epoch 21/50\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training LSTM: 100%|██████████| 6805/6805 [00:47<00:00, 143.91it/s, Loss=15.7874]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 1328.6567\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Validation: 100%|██████████| 1702/1702 [00:09<00:00, 181.48it/s, Val Loss=3787.7041]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Val Loss: 1301.5151, Overall RMSE: 36.06 W/m²\n",
            "RMSE per step: ['35.84', '35.94', '36.11', '36.33']\n",
            "New best model saved! RMSE: 36.06 W/m²\n",
            "\n",
            "Epoch 22/50\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training LSTM: 100%|██████████| 6805/6805 [00:47<00:00, 143.26it/s, Loss=22.0300]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 1337.3207\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Validation: 100%|██████████| 1702/1702 [00:09<00:00, 181.15it/s, Val Loss=3796.6311]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Val Loss: 1299.9611, Overall RMSE: 36.03 W/m²\n",
            "RMSE per step: ['35.82', '35.92', '36.09', '36.30']\n",
            "New best model saved! RMSE: 36.03 W/m²\n",
            "\n",
            "Epoch 23/50\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training LSTM: 100%|██████████| 6805/6805 [00:47<00:00, 143.58it/s, Loss=28.1921]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 1314.7421\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Validation: 100%|██████████| 1702/1702 [00:09<00:00, 180.37it/s, Val Loss=3728.9583]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Val Loss: 1284.3906, Overall RMSE: 35.82 W/m²\n",
            "RMSE per step: ['35.60', '35.70', '35.88', '36.09']\n",
            "New best model saved! RMSE: 35.82 W/m²\n",
            "\n",
            "Epoch 24/50\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training LSTM: 100%|██████████| 6805/6805 [00:47<00:00, 142.53it/s, Loss=1759.3823]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 1332.7222\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Validation: 100%|██████████| 1702/1702 [00:09<00:00, 174.61it/s, Val Loss=3904.5581]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Val Loss: 1336.1214, Overall RMSE: 36.53 W/m²\n",
            "RMSE per step: ['36.29', '36.42', '36.60', '36.81']\n",
            "\n",
            "Epoch 25/50\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training LSTM: 100%|██████████| 6805/6805 [00:47<00:00, 141.86it/s, Loss=5.1197]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 1307.3463\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Validation: 100%|██████████| 1702/1702 [00:09<00:00, 175.96it/s, Val Loss=3671.3960]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Val Loss: 1271.5219, Overall RMSE: 35.64 W/m²\n",
            "RMSE per step: ['35.43', '35.53', '35.69', '35.90']\n",
            "New best model saved! RMSE: 35.64 W/m²\n",
            "\n",
            "Epoch 26/50\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training LSTM: 100%|██████████| 6805/6805 [00:47<00:00, 142.04it/s, Loss=73.4651]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 1278.7492\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Validation: 100%|██████████| 1702/1702 [00:09<00:00, 179.10it/s, Val Loss=3650.2642]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Val Loss: 1266.7882, Overall RMSE: 35.57 W/m²\n",
            "RMSE per step: ['35.35', '35.46', '35.63', '35.84']\n",
            "New best model saved! RMSE: 35.57 W/m²\n",
            "\n",
            "Epoch 27/50\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training LSTM: 100%|██████████| 6805/6805 [00:49<00:00, 137.41it/s, Loss=1102.2528]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 1279.3948\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Validation: 100%|██████████| 1702/1702 [00:09<00:00, 173.29it/s, Val Loss=3731.4097]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Val Loss: 1290.6081, Overall RMSE: 35.91 W/m²\n",
            "RMSE per step: ['35.68', '35.80', '35.97', '36.17']\n",
            "\n",
            "Epoch 28/50\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training LSTM: 100%|██████████| 6805/6805 [00:50<00:00, 135.90it/s, Loss=75.4055]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 1271.4130\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Validation: 100%|██████████| 1702/1702 [00:09<00:00, 175.70it/s, Val Loss=3545.2273]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Val Loss: 1237.9551, Overall RMSE: 35.17 W/m²\n",
            "RMSE per step: ['34.95', '35.05', '35.22', '35.44']\n",
            "New best model saved! RMSE: 35.17 W/m²\n",
            "\n",
            "Epoch 29/50\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training LSTM: 100%|██████████| 6805/6805 [00:50<00:00, 136.03it/s, Loss=13.6593]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 1251.7722\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Validation: 100%|██████████| 1702/1702 [00:08<00:00, 192.07it/s, Val Loss=3478.8093]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Val Loss: 1219.4881, Overall RMSE: 34.90 W/m²\n",
            "RMSE per step: ['34.67', '34.79', '34.96', '35.19']\n",
            "New best model saved! RMSE: 34.90 W/m²\n",
            "\n",
            "Epoch 30/50\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training LSTM: 100%|██████████| 6805/6805 [00:49<00:00, 138.03it/s, Loss=17.9339]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 1237.7836\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Validation: 100%|██████████| 1702/1702 [00:08<00:00, 199.14it/s, Val Loss=3487.6440]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Val Loss: 1226.5003, Overall RMSE: 35.00 W/m²\n",
            "RMSE per step: ['34.76', '34.89', '35.07', '35.29']\n",
            "\n",
            "Epoch 31/50\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training LSTM: 100%|██████████| 6805/6805 [00:49<00:00, 138.36it/s, Loss=2480.9583]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 1234.6104\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Validation: 100%|██████████| 1702/1702 [00:08<00:00, 195.53it/s, Val Loss=3523.7981]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Val Loss: 1230.9383, Overall RMSE: 35.07 W/m²\n",
            "RMSE per step: ['34.83', '34.95', '35.13', '35.35']\n",
            "\n",
            "Epoch 32/50\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training LSTM: 100%|██████████| 6805/6805 [00:48<00:00, 139.08it/s, Loss=834.0339]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 1222.8271\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Validation: 100%|██████████| 1702/1702 [00:09<00:00, 185.23it/s, Val Loss=3240.4570]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Val Loss: 1167.0402, Overall RMSE: 34.14 W/m²\n",
            "RMSE per step: ['33.90', '34.02', '34.21', '34.44']\n",
            "New best model saved! RMSE: 34.14 W/m²\n",
            "\n",
            "Epoch 33/50\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training LSTM: 100%|██████████| 6805/6805 [00:49<00:00, 138.79it/s, Loss=1184.2429]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 1215.8425\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Validation: 100%|██████████| 1702/1702 [00:09<00:00, 179.28it/s, Val Loss=3463.2925]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Val Loss: 1218.7021, Overall RMSE: 34.89 W/m²\n",
            "RMSE per step: ['34.64', '34.77', '34.96', '35.18']\n",
            "\n",
            "Epoch 34/50\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training LSTM: 100%|██████████| 6805/6805 [00:48<00:00, 140.41it/s, Loss=236.1086]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 1253.8115\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Validation: 100%|██████████| 1702/1702 [00:09<00:00, 171.97it/s, Val Loss=3503.5327]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Val Loss: 1227.4087, Overall RMSE: 35.02 W/m²\n",
            "RMSE per step: ['34.80', '34.90', '35.08', '35.28']\n",
            "\n",
            "Epoch 35/50\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training LSTM: 100%|██████████| 6805/6805 [00:48<00:00, 140.32it/s, Loss=1002.6744]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 1227.1264\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Validation: 100%|██████████| 1702/1702 [00:09<00:00, 173.59it/s, Val Loss=3397.1924]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Val Loss: 1198.6554, Overall RMSE: 34.60 W/m²\n",
            "RMSE per step: ['34.38', '34.49', '34.66', '34.88']\n",
            "\n",
            "Epoch 36/50\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training LSTM: 100%|██████████| 6805/6805 [00:48<00:00, 140.67it/s, Loss=58.1402]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 1213.9555\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Validation: 100%|██████████| 1702/1702 [00:09<00:00, 173.94it/s, Val Loss=3431.3059]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Val Loss: 1206.4218, Overall RMSE: 34.72 W/m²\n",
            "RMSE per step: ['34.48', '34.60', '34.78', '35.01']\n",
            "\n",
            "Epoch 37/50\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training LSTM: 100%|██████████| 6805/6805 [00:48<00:00, 140.31it/s, Loss=2149.0564]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 1210.1930\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Validation: 100%|██████████| 1702/1702 [00:09<00:00, 173.96it/s, Val Loss=3341.1013]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Val Loss: 1184.7600, Overall RMSE: 34.40 W/m²\n",
            "RMSE per step: ['34.17', '34.29', '34.47', '34.69']\n",
            "\n",
            "Epoch 38/50\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training LSTM: 100%|██████████| 6805/6805 [00:48<00:00, 140.53it/s, Loss=29.3420]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 1196.1810\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Validation: 100%|██████████| 1702/1702 [00:09<00:00, 172.09it/s, Val Loss=3424.4338]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Val Loss: 1208.0699, Overall RMSE: 34.74 W/m²\n",
            "RMSE per step: ['34.51', '34.62', '34.80', '35.02']\n",
            "\n",
            "Epoch 39/50\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training LSTM: 100%|██████████| 6805/6805 [00:48<00:00, 139.02it/s, Loss=834.6226]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 1219.6151\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Validation: 100%|██████████| 1702/1702 [00:09<00:00, 173.19it/s, Val Loss=3375.5356]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Val Loss: 1196.8569, Overall RMSE: 34.58 W/m²\n",
            "RMSE per step: ['34.33', '34.46', '34.64', '34.87']\n",
            "\n",
            "Epoch 40/50\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training LSTM: 100%|██████████| 6805/6805 [00:48<00:00, 139.46it/s, Loss=65.2264]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 1198.3255\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Validation: 100%|██████████| 1702/1702 [00:09<00:00, 174.99it/s, Val Loss=3334.5774]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Val Loss: 1186.9869, Overall RMSE: 34.43 W/m²\n",
            "RMSE per step: ['34.19', '34.32', '34.50', '34.73']\n",
            "\n",
            "Epoch 41/50\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training LSTM: 100%|██████████| 6805/6805 [00:49<00:00, 137.36it/s, Loss=1230.0200]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 1209.5461\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Validation: 100%|██████████| 1702/1702 [00:09<00:00, 177.32it/s, Val Loss=3375.7451]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Val Loss: 1194.6133, Overall RMSE: 34.54 W/m²\n",
            "RMSE per step: ['34.30', '34.42', '34.61', '34.84']\n",
            "\n",
            "Epoch 42/50\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training LSTM: 100%|██████████| 6805/6805 [00:51<00:00, 133.00it/s, Loss=17.7356]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 1199.5345\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Validation: 100%|██████████| 1702/1702 [00:08<00:00, 193.77it/s, Val Loss=3383.1992]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Val Loss: 1196.2557, Overall RMSE: 34.57 W/m²\n",
            "RMSE per step: ['34.33', '34.45', '34.64', '34.85']\n",
            "\n",
            "Epoch 43/50\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training LSTM: 100%|██████████| 6805/6805 [00:50<00:00, 133.81it/s, Loss=133.4335]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 1188.6568\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Validation: 100%|██████████| 1702/1702 [00:09<00:00, 189.03it/s, Val Loss=3365.1323]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Val Loss: 1194.4940, Overall RMSE: 34.54 W/m²\n",
            "RMSE per step: ['34.30', '34.42', '34.61', '34.83']\n",
            "\n",
            "Epoch 44/50\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training LSTM: 100%|██████████| 6805/6805 [00:50<00:00, 135.19it/s, Loss=1150.5085]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 1148.0907\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Validation: 100%|██████████| 1702/1702 [00:09<00:00, 178.95it/s, Val Loss=3078.3669]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Val Loss: 1116.7151, Overall RMSE: 33.40 W/m²\n",
            "RMSE per step: ['33.16', '33.28', '33.46', '33.70']\n",
            "New best model saved! RMSE: 33.40 W/m²\n",
            "\n",
            "Epoch 45/50\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training LSTM: 100%|██████████| 6805/6805 [00:49<00:00, 136.74it/s, Loss=30.1654]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 1133.2117\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Validation: 100%|██████████| 1702/1702 [00:09<00:00, 172.33it/s, Val Loss=3099.9175]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Val Loss: 1121.0602, Overall RMSE: 33.47 W/m²\n",
            "RMSE per step: ['33.22', '33.34', '33.53', '33.76']\n",
            "\n",
            "Epoch 46/50\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training LSTM: 100%|██████████| 6805/6805 [00:49<00:00, 137.11it/s, Loss=3390.3877]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 1152.0660\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Validation: 100%|██████████| 1702/1702 [00:10<00:00, 168.92it/s, Val Loss=3156.6538]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Val Loss: 1136.5915, Overall RMSE: 33.70 W/m²\n",
            "RMSE per step: ['33.46', '33.58', '33.76', '33.98']\n",
            "\n",
            "Epoch 47/50\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training LSTM: 100%|██████████| 6805/6805 [00:50<00:00, 135.78it/s, Loss=2120.8308]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 1150.1703\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Validation: 100%|██████████| 1702/1702 [00:10<00:00, 166.31it/s, Val Loss=3155.5850]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Val Loss: 1137.4462, Overall RMSE: 33.71 W/m²\n",
            "RMSE per step: ['33.48', '33.59', '33.77', '33.99']\n",
            "\n",
            "Epoch 48/50\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training LSTM: 100%|██████████| 6805/6805 [00:49<00:00, 137.29it/s, Loss=2140.0386]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 1148.0806\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Validation: 100%|██████████| 1702/1702 [00:10<00:00, 162.65it/s, Val Loss=3161.9502]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Val Loss: 1137.9505, Overall RMSE: 33.72 W/m²\n",
            "RMSE per step: ['33.50', '33.60', '33.77', '33.99']\n",
            "\n",
            "Epoch 49/50\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training LSTM: 100%|██████████| 6805/6805 [00:50<00:00, 134.41it/s, Loss=160.1369]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 1163.6172\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Validation: 100%|██████████| 1702/1702 [00:10<00:00, 168.16it/s, Val Loss=3199.1455]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Val Loss: 1147.3094, Overall RMSE: 33.85 W/m²\n",
            "RMSE per step: ['33.62', '33.73', '33.92', '34.15']\n",
            "\n",
            "Epoch 50/50\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training LSTM: 100%|██████████| 6805/6805 [00:50<00:00, 134.75it/s, Loss=15.0220]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 1175.5708\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Validation: 100%|██████████| 1702/1702 [00:09<00:00, 178.86it/s, Val Loss=3267.4819]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Val Loss: 1166.1147, Overall RMSE: 34.13 W/m²\n",
            "RMSE per step: ['33.89', '34.01', '34.20', '34.43']\n",
            "LSTM training completed!\n",
            "LSTM forecasting training completed!\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
        "import json\n",
        "\n",
        "def load_multi_day_irradiance(files):\n",
        "    \"\"\"Load and concatenate irradiance data from multiple CSV files\"\"\"\n",
        "    all_values = []\n",
        "    for f in files:\n",
        "        df = pd.read_csv(f)\n",
        "        values = df.iloc[:, 1].values.astype(np.float32)\n",
        "        all_values.extend(values)\n",
        "    return np.array(all_values)\n",
        "\n",
        "class MultiDayTimeSeriesDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, irradiance_files, sequence_length, forecast_horizon):\n",
        "        self.sequence_length = sequence_length\n",
        "        self.forecast_horizon = forecast_horizon\n",
        "        self.irradiance = load_multi_day_irradiance(irradiance_files)\n",
        "        self.length = len(self.irradiance) - sequence_length - forecast_horizon + 1\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.length\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        seq = self.irradiance[idx:idx+self.sequence_length]\n",
        "        target = self.irradiance[idx+self.sequence_length:idx+self.sequence_length+self.forecast_horizon]\n",
        "        seq = torch.tensor(seq, dtype=torch.float32).unsqueeze(-1)\n",
        "        target = torch.tensor(target, dtype=torch.float32)\n",
        "        return seq, target\n",
        "\n",
        "class LSTMTrainer:\n",
        "    \"\"\"\n",
        "    Trainer class for LSTM forecasting model following paper methodology\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, config=None):\n",
        "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "        print(f\"Using device: {self.device}\")\n",
        "\n",
        "        # Default configuration based on paper\n",
        "        self.config = {\n",
        "            'sequence_length': 20,\n",
        "            'forecast_horizon': 4,\n",
        "            'learning_rate': 1e-4,\n",
        "            'batch_size': 64,\n",
        "            'num_epochs': 5,\n",
        "            'lstm_hidden_size': 128,\n",
        "            'lstm_num_layers': 2,\n",
        "            'dropout': 0.2,\n",
        "            'weight_decay': 1e-4,\n",
        "            'scheduler_patience': 10,\n",
        "            'early_stopping_patience': 15,\n",
        "            'save_dir': 'models',\n",
        "            'log_dir': 'logs'\n",
        "        }\n",
        "\n",
        "        if config:\n",
        "            self.config.update(config)\n",
        "\n",
        "        # Create directories\n",
        "        os.makedirs(self.config['save_dir'], exist_ok=True)\n",
        "        os.makedirs(self.config['log_dir'], exist_ok=True)\n",
        "\n",
        "        # Initialize model\n",
        "        self.model = SolarLSTMForecasting(\n",
        "            input_size=1,\n",
        "            hidden_size=self.config['lstm_hidden_size'],\n",
        "            num_layers=self.config['lstm_num_layers'],\n",
        "            output_size=self.config['forecast_horizon'],\n",
        "            dropout=self.config['dropout']\n",
        "        ).to(self.device)\n",
        "\n",
        "        # Initialize optimizer and scheduler\n",
        "        self.optimizer = optim.Adam(\n",
        "            self.model.parameters(),\n",
        "            lr=self.config['learning_rate'],\n",
        "            weight_decay=self.config['weight_decay']\n",
        "        )\n",
        "\n",
        "        self.scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
        "            self.optimizer,\n",
        "            mode='min',\n",
        "            patience=self.config['scheduler_patience'],\n",
        "            factor=0.5\n",
        "        )\n",
        "\n",
        "        self.criterion = nn.MSELoss()\n",
        "\n",
        "        # Training history\n",
        "        self.train_losses = []\n",
        "        self.val_losses = []\n",
        "        self.best_val_loss = float('inf')\n",
        "        self.patience_counter = 0\n",
        "\n",
        "    def train_epoch(self, train_loader):\n",
        "        \"\"\"Train for one epoch\"\"\"\n",
        "        self.model.train()\n",
        "        total_loss = 0.0\n",
        "        num_batches = 0\n",
        "\n",
        "        with tqdm(train_loader, desc=\"Training LSTM\") as pbar:\n",
        "            for batch_idx, (sequences, targets) in enumerate(pbar):\n",
        "                sequences, targets = sequences.to(self.device), targets.to(self.device)\n",
        "\n",
        "                self.optimizer.zero_grad()\n",
        "\n",
        "                outputs = self.model(sequences)\n",
        "                loss = self.criterion(outputs, targets)\n",
        "\n",
        "                loss.backward()\n",
        "                torch.nn.utils.clip_grad_norm_(self.model.parameters(), max_norm=1.0)\n",
        "                self.optimizer.step()\n",
        "\n",
        "                total_loss += loss.item()\n",
        "                num_batches += 1\n",
        "\n",
        "                pbar.set_postfix({'Loss': f'{loss.item():.4f}'})\n",
        "\n",
        "        return total_loss / num_batches\n",
        "\n",
        "    def validate_epoch(self, val_loader):\n",
        "        \"\"\"Validate for one epoch\"\"\"\n",
        "        self.model.eval()\n",
        "        total_loss = 0.0\n",
        "        all_predictions = []\n",
        "        all_targets = []\n",
        "\n",
        "        with torch.no_grad():\n",
        "            with tqdm(val_loader, desc=\"Validation\") as pbar:\n",
        "                for sequences, targets in pbar:\n",
        "                    sequences, targets = sequences.to(self.device), targets.to(self.device)\n",
        "\n",
        "                    outputs = self.model(sequences)\n",
        "                    loss = self.criterion(outputs, targets)\n",
        "\n",
        "                    total_loss += loss.item()\n",
        "\n",
        "                    all_predictions.append(outputs.cpu().numpy())\n",
        "                    all_targets.append(targets.cpu().numpy())\n",
        "\n",
        "                    pbar.set_postfix({'Val Loss': f'{loss.item():.4f}'})\n",
        "\n",
        "        avg_loss = total_loss / len(val_loader)\n",
        "\n",
        "        predictions = np.concatenate(all_predictions, axis=0)\n",
        "        targets = np.concatenate(all_targets, axis=0)\n",
        "\n",
        "        rmse_per_step = []\n",
        "        mae_per_step = []\n",
        "\n",
        "        for step in range(self.config['forecast_horizon']):\n",
        "            step_pred = predictions[:, step]\n",
        "            step_target = targets[:, step]\n",
        "            mse = mean_squared_error(step_target, step_pred)\n",
        "            rmse = np.sqrt(mse)\n",
        "            mae = mean_absolute_error(step_target, step_pred)\n",
        "            rmse_per_step.append(rmse)\n",
        "            mae_per_step.append(mae)\n",
        "\n",
        "        overall_rmse = np.sqrt(mean_squared_error(targets.flatten(), predictions.flatten()))\n",
        "        overall_mae = mean_absolute_error(targets.flatten(), predictions.flatten())\n",
        "\n",
        "        return avg_loss, overall_rmse, overall_mae, rmse_per_step, mae_per_step\n",
        "\n",
        "    def train(self, train_loader, val_loader=None):\n",
        "        \"\"\"Main training loop\"\"\"\n",
        "        print(f\"Starting LSTM training for {self.config['num_epochs']} epochs...\")\n",
        "        print(f\"Model parameters: {sum(p.numel() for p in self.model.parameters()):,}\")\n",
        "        print(f\"Sequence length: {self.config['sequence_length']}, Forecast horizon: {self.config['forecast_horizon']}\")\n",
        "\n",
        "        for epoch in range(self.config['num_epochs']):\n",
        "            print(f\"\\nEpoch {epoch+1}/{self.config['num_epochs']}\")\n",
        "\n",
        "            train_loss = self.train_epoch(train_loader)\n",
        "            self.train_losses.append(train_loss)\n",
        "            print(f\"Train Loss: {train_loss:.4f}\")\n",
        "\n",
        "            if val_loader is not None:\n",
        "                val_loss, overall_rmse, overall_mae, rmse_per_step, mae_per_step = self.validate_epoch(val_loader)\n",
        "                self.val_losses.append(val_loss)\n",
        "\n",
        "                print(f\"Val Loss: {val_loss:.4f}, Overall RMSE: {overall_rmse:.2f} W/m²\")\n",
        "                print(f\"RMSE per step: {[f'{r:.2f}' for r in rmse_per_step]}\")\n",
        "\n",
        "                self.scheduler.step(val_loss)\n",
        "\n",
        "                if val_loss < self.best_val_loss:\n",
        "                    self.best_val_loss = val_loss\n",
        "                    self.patience_counter = 0\n",
        "\n",
        "                    torch.save({\n",
        "                        'epoch': epoch,\n",
        "                        'model_state_dict': self.model.state_dict(),\n",
        "                        'optimizer_state_dict': self.optimizer.state_dict(),\n",
        "                        'val_loss': val_loss,\n",
        "                        'rmse': overall_rmse,\n",
        "                        'config': self.config\n",
        "                    }, os.path.join(self.config['save_dir'], 'best_lstm_model.pth'))\n",
        "\n",
        "                    print(f\"New best model saved! RMSE: {overall_rmse:.2f} W/m²\")\n",
        "                else:\n",
        "                    self.patience_counter += 1\n",
        "\n",
        "                if self.patience_counter >= self.config['early_stopping_patience']:\n",
        "                    print(f\"Early stopping triggered after {epoch+1} epochs\")\n",
        "                    break\n",
        "\n",
        "        torch.save({\n",
        "            'epoch': epoch,\n",
        "            'model_state_dict': self.model.state_dict(),\n",
        "            'optimizer_state_dict': self.optimizer.state_dict(),\n",
        "            'train_losses': self.train_losses,\n",
        "            'val_losses': self.val_losses\n",
        "        }, os.path.join(self.config['save_dir'], 'final_lstm_model.pth'))\n",
        "\n",
        "        history = {\n",
        "            'train_losses': self.train_losses,\n",
        "            'val_losses': self.val_losses,\n",
        "            'config': self.config\n",
        "        }\n",
        "\n",
        "        with open(os.path.join(self.config['log_dir'], 'lstm_training_history.json'), 'w') as f:\n",
        "            json.dump(history, f, indent=2)\n",
        "\n",
        "        print(\"LSTM training completed!\")\n",
        "        return self.train_losses, self.val_losses\n",
        "\n",
        "    def load_model(self, checkpoint_path):\n",
        "        checkpoint = torch.load(checkpoint_path, map_location=self.device)\n",
        "        self.model.load_state_dict(checkpoint['model_state_dict'])\n",
        "        return checkpoint\n",
        "\n",
        "    def evaluate(self, test_loader):\n",
        "        self.model.eval()\n",
        "        all_predictions = []\n",
        "        all_targets = []\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for sequences, targets in tqdm(test_loader, desc=\"Evaluating LSTM\"):\n",
        "                sequences, targets = sequences.to(self.device), targets.to(self.device)\n",
        "                outputs = self.model(sequences)\n",
        "                all_predictions.append(outputs.cpu().numpy())\n",
        "                all_targets.append(targets.cpu().numpy())\n",
        "\n",
        "        predictions = np.concatenate(all_predictions, axis=0)\n",
        "        targets = np.concatenate(all_targets, axis=0)\n",
        "\n",
        "        overall_rmse = np.sqrt(mean_squared_error(targets.flatten(), predictions.flatten()))\n",
        "        overall_mae = mean_absolute_error(targets.flatten(), predictions.flatten())\n",
        "\n",
        "        rmse_per_step = []\n",
        "        for step in range(self.config['forecast_horizon']):\n",
        "            step_rmse = np.sqrt(mean_squared_error(targets[:, step], predictions[:, step]))\n",
        "            rmse_per_step.append(step_rmse)\n",
        "\n",
        "        print(f\"Test Results - Overall RMSE: {overall_rmse:.2f} W/m²\")\n",
        "        print(f\"RMSE per forecast step: {[f'{r:.2f}' for r in rmse_per_step]}\")\n",
        "\n",
        "        return overall_rmse, overall_mae, rmse_per_step, predictions, targets\n",
        "\n",
        "def train_lstm_forecasting():\n",
        "    \"\"\"Main function to train LSTM forecasting model\"\"\"\n",
        "\n",
        "    # Configuration\n",
        "    config = {\n",
        "        'sequence_length': 20,\n",
        "        'forecast_horizon': 4,\n",
        "        'learning_rate': 1e-4,\n",
        "        'batch_size': 64,\n",
        "        'num_epochs': 50,\n",
        "        'irradiance_files': [\n",
        "            '/content/drive/MyDrive/GIRASOL_DATASET/2019_01_15/pyranometer/2019_01_15.csv',\n",
        "            '/content/drive/MyDrive/GIRASOL_DATASET/2019_01_16/pyranometer/2019_01_16.csv',\n",
        "            '/content/drive/MyDrive/GIRASOL_DATASET/2019_01_17/pyranometer/2019_01_17.csv',\n",
        "            '/content/drive/MyDrive/GIRASOL_DATASET/2019_01_18/pyranometer/2019_01_18.csv',\n",
        "            '/content/drive/MyDrive/GIRASOL_DATASET/2019_01_19/pyranometer/2019_01_19.csv',\n",
        "            '/content/drive/MyDrive/GIRASOL_DATASET/2019_01_20/pyranometer/2019_01_20.csv'\n",
        "            # Add more days as needed\n",
        "        ]\n",
        "    }\n",
        "\n",
        "    # Create dataset\n",
        "    print(\"Loading multi-day time series dataset...\")\n",
        "    dataset = MultiDayTimeSeriesDataset(\n",
        "        irradiance_files=config['irradiance_files'],\n",
        "        sequence_length=config['sequence_length'],\n",
        "        forecast_horizon=config['forecast_horizon']\n",
        "    )\n",
        "\n",
        "    # Split dataset\n",
        "    train_size = int(0.8 * len(dataset))\n",
        "    val_size = len(dataset) - train_size\n",
        "\n",
        "    train_dataset, val_dataset = torch.utils.data.random_split(\n",
        "        dataset, [train_size, val_size]\n",
        "    )\n",
        "\n",
        "    train_loader = DataLoader(\n",
        "        train_dataset,\n",
        "        batch_size=config['batch_size'],\n",
        "        shuffle=True,\n",
        "        num_workers=2\n",
        "    )\n",
        "\n",
        "    val_loader = DataLoader(\n",
        "        val_dataset,\n",
        "        batch_size=config['batch_size'],\n",
        "        shuffle=False,\n",
        "        num_workers=2\n",
        "    )\n",
        "\n",
        "    print(f\"Train samples: {len(train_dataset)}, Val samples: {len(val_dataset)}\")\n",
        "\n",
        "    trainer = LSTMTrainer(config=config)\n",
        "    train_losses, val_losses = trainer.train(train_loader, val_loader)\n",
        "\n",
        "    print(\"LSTM forecasting training completed!\")\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    train_lstm_forecasting()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
