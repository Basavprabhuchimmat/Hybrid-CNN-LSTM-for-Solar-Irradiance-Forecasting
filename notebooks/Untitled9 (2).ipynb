{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "sys.path.append('/content/drive/MyDrive/scripts')"
      ],
      "metadata": {
        "id": "NMFu98AiDxlr"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import cv2\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from tqdm import tqdm\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
        "import matplotlib.pyplot as plt\n",
        "from torchvision import models, transforms\n",
        "\n",
        "\n",
        "\n",
        "class MultiDayDataset(Dataset):\n",
        "    def __init__(self, image_paths, irradiance_values, target_size=(224,224)):\n",
        "        self.image_paths = image_paths\n",
        "        self.irradiance_values = irradiance_values\n",
        "        self.transform = transforms.Compose([\n",
        "            transforms.ToPILImage(),\n",
        "            transforms.Resize(target_size),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                                 std=[0.229, 0.224, 0.225])\n",
        "        ])\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_paths)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path = self.image_paths[idx]\n",
        "        img = cv2.imread(img_path)\n",
        "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "        img_tensor = self.transform(img)\n",
        "        irradiance = torch.tensor(self.irradiance_values[idx], dtype=torch.float32)\n",
        "        return img_tensor, irradiance\n",
        "\n",
        "def get_multi_day_dataset(image_dirs, irradiance_files):\n",
        "    image_paths = []\n",
        "    irradiance_values = []\n",
        "    for img_dir, irr_file in zip(image_dirs, irradiance_files):\n",
        "        if irr_file.endswith('.csv'):\n",
        "            df = pd.read_csv(irr_file)\n",
        "            values = df.iloc[:, 1].values.astype(np.float32)\n",
        "        else:\n",
        "            values = np.loadtxt(irr_file, delimiter=',')[:, 1].astype(np.float32)\n",
        "\n",
        "        files = sorted([f for f in os.listdir(img_dir) if f.endswith(('.png', '.jpg', '.jpeg'))])\n",
        "        files = files[:len(values)]\n",
        "        image_paths.extend([os.path.join(img_dir, f) for f in files])\n",
        "        irradiance_values.extend(values[:len(files)])\n",
        "    return MultiDayDataset(image_paths, irradiance_values)\n",
        "\n",
        "\n",
        "class EfficientNetRegression(nn.Module):\n",
        "    def __init__(self, num_classes=1, model_name='efficientnet_b0', pretrained=True):\n",
        "        super(EfficientNetRegression, self).__init__()\n",
        "        # Use weights argument instead of pretrained\n",
        "        if pretrained:\n",
        "            weights = models.EfficientNet_B0_Weights.IMAGENET1K_V1\n",
        "        else:\n",
        "            weights = None\n",
        "        backbone = getattr(models, model_name)(weights=weights)\n",
        "        self.features = backbone.features\n",
        "        self.pooling = nn.AdaptiveAvgPool2d(1)\n",
        "        in_features = backbone.classifier[1].in_features\n",
        "        self.regressor = nn.Sequential(\n",
        "            nn.Flatten(),\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(in_features, 256),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(0.3),\n",
        "            nn.Linear(256, 128),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Linear(128, num_classes)\n",
        "        )\n",
        "    def forward(self, x):\n",
        "        x = self.features(x)\n",
        "        x = self.pooling(x)\n",
        "        x = self.regressor(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "\n",
        "class CNNTrainer:\n",
        "    def __init__(self, config=None):\n",
        "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "        print(f\"Using device: {self.device}\")\n",
        "        self.config = {\n",
        "            'learning_rate': 1e-4,\n",
        "            'batch_size': 64,\n",
        "            'num_epochs': 20,\n",
        "            'weight_decay': 1e-4,\n",
        "            'scheduler_patience': 5,\n",
        "            'early_stopping_patience': 10,\n",
        "            'save_dir': 'models',\n",
        "            'log_dir': 'logs'\n",
        "        }\n",
        "        if config:\n",
        "            self.config.update(config)\n",
        "        os.makedirs(self.config['save_dir'], exist_ok=True)\n",
        "        os.makedirs(self.config['log_dir'], exist_ok=True)\n",
        "        self.model = EfficientNetRegression().to(self.device)\n",
        "        self.optimizer = optim.Adam(self.model.parameters(),\n",
        "                                    lr=self.config['learning_rate'],\n",
        "                                    weight_decay=self.config['weight_decay'])\n",
        "        self.scheduler = optim.lr_scheduler.ReduceLROnPlateau(self.optimizer,\n",
        "                                                             mode='min',\n",
        "                                                             patience=self.config['scheduler_patience'],\n",
        "                                                             factor=0.5)\n",
        "        self.criterion = nn.MSELoss()\n",
        "        self.train_losses = []\n",
        "        self.val_losses = []\n",
        "        self.best_val_loss = float('inf')\n",
        "        self.patience_counter = 0\n",
        "\n",
        "    def train_epoch(self, train_loader):\n",
        "        self.model.train()\n",
        "        total_loss = 0.0\n",
        "        with tqdm(train_loader, desc=\"Training\") as pbar:\n",
        "            for images, targets in pbar:\n",
        "                images, targets = images.to(self.device), targets.to(self.device)\n",
        "                self.optimizer.zero_grad()\n",
        "                outputs = self.model(images)\n",
        "                loss = self.criterion(outputs.squeeze(), targets)\n",
        "                loss.backward()\n",
        "                self.optimizer.step()\n",
        "                total_loss += loss.item()\n",
        "                pbar.set_postfix({'Loss': f'{loss.item():.4f}'})\n",
        "        return total_loss / len(train_loader)\n",
        "\n",
        "    def validate_epoch(self, val_loader):\n",
        "        self.model.eval()\n",
        "        total_loss = 0.0\n",
        "        predictions, targets_all = [], []\n",
        "        with torch.no_grad():\n",
        "            with tqdm(val_loader, desc=\"Validation\") as pbar:\n",
        "                for images, targets in pbar:\n",
        "                    images, targets = images.to(self.device), targets.to(self.device)\n",
        "                    outputs = self.model(images)\n",
        "                    loss = self.criterion(outputs.squeeze(), targets)\n",
        "                    total_loss += loss.item()\n",
        "                    predictions.extend(outputs.squeeze().cpu().numpy())\n",
        "                    targets_all.extend(targets.cpu().numpy())\n",
        "                    pbar.set_postfix({'Val Loss': f'{loss.item():.4f}'})\n",
        "        avg_loss = total_loss / len(val_loader)\n",
        "        predictions = np.array(predictions)\n",
        "        targets_all = np.array(targets_all)\n",
        "        rmse = np.sqrt(mean_squared_error(targets_all, predictions))\n",
        "        mae = mean_absolute_error(targets_all, predictions)\n",
        "        return avg_loss, rmse, mae\n",
        "\n",
        "    def train(self, train_loader, val_loader):\n",
        "        print(f\"Starting training for {self.config['num_epochs']} epochs...\")\n",
        "        print(f\"Model parameters: {sum(p.numel() for p in self.model.parameters()):,}\")\n",
        "        for epoch in range(self.config['num_epochs']):\n",
        "            print(f\"\\nEpoch {epoch+1}/{self.config['num_epochs']}\")\n",
        "            train_loss = self.train_epoch(train_loader)\n",
        "            self.train_losses.append(train_loss)\n",
        "            print(f\"Train Loss: {train_loss:.4f}\")\n",
        "            val_loss, rmse, mae = self.validate_epoch(val_loader)\n",
        "            self.val_losses.append(val_loss)\n",
        "            print(f\"Val Loss: {val_loss:.4f}, RMSE: {rmse:.2f}, MAE: {mae:.2f}\")\n",
        "            self.scheduler.step(val_loss)\n",
        "            if val_loss < self.best_val_loss:\n",
        "                self.best_val_loss = val_loss\n",
        "                self.patience_counter = 0\n",
        "                torch.save({\n",
        "                    'epoch': epoch,\n",
        "                    'model_state_dict': self.model.state_dict(),\n",
        "                    'optimizer_state_dict': self.optimizer.state_dict(),\n",
        "                    'val_loss': val_loss,\n",
        "                    'config': self.config\n",
        "                }, os.path.join(self.config['save_dir'], 'best_efficientnet_model.pth'))\n",
        "                print(f\"New best model saved!\")\n",
        "            else:\n",
        "                self.patience_counter += 1\n",
        "            if self.patience_counter >= self.config['early_stopping_patience']:\n",
        "                print(f\"Early stopping triggered after {epoch+1} epochs\")\n",
        "                break\n",
        "        plt.figure(figsize=(10,6))\n",
        "        plt.plot(self.train_losses, label='Train Loss')\n",
        "        plt.plot(self.val_losses, label='Validation Loss')\n",
        "        plt.xlabel('Epoch')\n",
        "        plt.ylabel('MSE Loss')\n",
        "        plt.title('EfficientNet Training Progress')\n",
        "        plt.legend()\n",
        "        plt.grid(True)\n",
        "        plt.show()\n",
        "\n",
        "\n",
        "# def train_efficientnet_nowcasting():\n",
        "#     config = {\n",
        "#         'learning_rate': 1e-4,\n",
        "#         'batch_size': 64,\n",
        "#         'num_epochs': 25,\n",
        "#         'image_dirs': [\n",
        "#             '/content/drive/MyDrive/data/processed/2019_01_15',\n",
        "#             '/content/drive/MyDrive/data/processed/2019_01_16',\n",
        "#             '/content/drive/MyDrive/data/processed/2019_01_17',\n",
        "#             '/content/drive/MyDrive/data/processed/2019_01_18',\n",
        "#             '/content/drive/MyDrive/data/processed/2019_01_19',\n",
        "#             '/content/drive/MyDrive/data/processed/2019_01_20'\n",
        "\n",
        "#         ],\n",
        "#         'irradiance_files': [\n",
        "#             '/content/drive/MyDrive/GIRASOL_DATASET/2019_01_15/pyranometer/2019_01_15.csv',\n",
        "#             '/content/drive/MyDrive/GIRASOL_DATASET/2019_01_16/pyranometer/2019_01_16.csv',\n",
        "#             '/content/drive/MyDrive/GIRASOL_DATASET/2019_01_17/pyranometer/2019_01_17.csv',\n",
        "#             '/content/drive/MyDrive/GIRASOL_DATASET/2019_01_18/pyranometer/2019_01_18.csv',\n",
        "#             '/content/drive/MyDrive/GIRASOL_DATASET/2019_01_19/pyranometer/2019_01_19.csv',\n",
        "#             '/content/drive/MyDrive/GIRASOL_DATASET/2019_01_20/pyranometer/2019_01_20.csv',\n",
        "\n",
        "#         ]\n",
        "#     }\n",
        "#     print(\"Loading multi-day dataset...\")\n",
        "#     dataset = get_multi_day_dataset(config['image_dirs'], config['irradiance_files'])\n",
        "#     train_size = int(0.8 * len(dataset))\n",
        "#     val_size = len(dataset) - train_size\n",
        "#     train_dataset, val_dataset = torch.utils.data.random_split(dataset, [train_size, val_size])\n",
        "#     train_loader = DataLoader(train_dataset, batch_size=config['batch_size'], shuffle=True, num_workers=2)\n",
        "#     val_loader = DataLoader(val_dataset, batch_size=config['batch_size'], shuffle=False, num_workers=2)\n",
        "#     print(f\"Train samples: {len(train_dataset)}, Val samples: {len(val_dataset)}\")\n",
        "#     trainer = CNNTrainer(config=config)\n",
        "#     trainer.train(train_loader, val_loader)\n",
        "#     print(\"EfficientNet nowcasting training completed!\")\n",
        "\n",
        "# # ============================\n",
        "# # 6. Run Training\n",
        "# # ============================\n",
        "# train_efficientnet_nowcasting()"
      ],
      "metadata": {
        "id": "DqtKABAOpbus"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "gV-r-qn5Db3F"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import torch\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import json\n",
        "from datetime import datetime\n",
        "import torch.nn as nn\n",
        "import torch.serialization\n",
        "\n",
        "from cnn_model import SolarCNNRegression, SolarCNNWithFeatureExtraction\n",
        "from lstm_model import HybridCNNLSTM\n",
        "from solar_datasets import SolarIrradianceDataset, SolarTimeSeriesDataset, SolarSequenceDataset\n",
        "\n",
        "\n",
        "# ---------------------------\n",
        "# Dataset\n",
        "# ---------------------------\n",
        "class MultiDayTimeSeriesDataset(Dataset):\n",
        "    def __init__(self, irradiance_file, sequence_length=20, forecast_horizon=4, value_col_index=1):\n",
        "        df = pd.read_csv(irradiance_file)\n",
        "        vals = df.iloc[:, value_col_index].astype(np.float32).values\n",
        "        self.series = vals\n",
        "        self.seq_len = sequence_length\n",
        "        self.horizon = forecast_horizon\n",
        "        self.length = len(self.series) - self.seq_len - self.horizon + 1\n",
        "        if self.length < 1:\n",
        "            raise ValueError(\"Not enough data samples for given sequence_length + forecast_horizon.\")\n",
        "    def __len__(self):\n",
        "        return self.length\n",
        "    def __getitem__(self, idx):\n",
        "        seq = self.series[idx : idx + self.seq_len]\n",
        "        tgt = self.series[idx + self.seq_len : idx + self.seq_len + self.horizon]\n",
        "        seq = torch.tensor(seq, dtype=torch.float32).unsqueeze(-1)\n",
        "        tgt = torch.tensor(tgt, dtype=torch.float32)\n",
        "        return seq, tgt\n",
        "\n",
        "\n",
        "# ---------------------------\n",
        "# LSTM Model\n",
        "# ---------------------------\n",
        "class SolarLSTMForecasting(nn.Module):\n",
        "    def __init__(self, input_size=1, hidden_size=128, num_layers=2, output_size=4, dropout=0.2):\n",
        "        super(SolarLSTMForecasting, self).__init__()\n",
        "        self.lstm = nn.LSTM(input_size=input_size,\n",
        "                            hidden_size=hidden_size,\n",
        "                            num_layers=num_layers,\n",
        "                            batch_first=True,\n",
        "                            dropout=dropout if num_layers > 1 else 0.0)\n",
        "        self.fc = nn.Linear(hidden_size, output_size)\n",
        "    def forward(self, x):\n",
        "        out, _ = self.lstm(x)\n",
        "        last = out[:, -1, :]\n",
        "        return self.fc(last)\n",
        "\n",
        "\n",
        "# ---------------------------\n",
        "# Safe checkpoint loader\n",
        "# ---------------------------\n",
        "def safe_load_checkpoint(model, model_path, device):\n",
        "    import torch.serialization\n",
        "    import numpy as np\n",
        "    try:\n",
        "        torch.serialization.add_safe_globals([np.core.multiarray.scalar, np.dtype, np.float64])\n",
        "    except Exception:\n",
        "        pass\n",
        "\n",
        "    ckpt = torch.load(model_path, map_location=device, weights_only=False)\n",
        "    if isinstance(ckpt, dict) and 'model_state_dict' in ckpt:\n",
        "        state_dict = ckpt['model_state_dict']\n",
        "    elif isinstance(ckpt, dict):\n",
        "        state_dict = ckpt\n",
        "    else:\n",
        "        raise RuntimeError(\"Unexpected checkpoint format.\")\n",
        "\n",
        "    model_dict = model.state_dict()\n",
        "    filtered = {}\n",
        "    skipped = []\n",
        "    for k, v in state_dict.items():\n",
        "        if k in model_dict:\n",
        "            if isinstance(v, torch.Tensor) and v.shape == model_dict[k].shape:\n",
        "                filtered[k] = v\n",
        "            else:\n",
        "                skipped.append((k, getattr(v, 'shape', None), model_dict[k].shape))\n",
        "    model_dict.update(filtered)\n",
        "    model.load_state_dict(model_dict)\n",
        "    if skipped:\n",
        "        print(\"Warning: some keys were skipped due to shape mismatch:\")\n",
        "        for item in skipped[:10]:\n",
        "            print(\"  \", item)\n",
        "    return ckpt\n",
        "\n",
        "\n",
        "# ---------------------------\n",
        "# Evaluation class\n",
        "# ---------------------------\n",
        "class ModelEvaluator:\n",
        "    def __init__(self, device=None):\n",
        "        self.device = device or torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "        print(f\"Using device: {self.device}\")\n",
        "        self.results = {}\n",
        "\n",
        "    def load_model(self, model_class, checkpoint_path, **kwargs):\n",
        "        model = model_class(**kwargs).to(self.device)\n",
        "        checkpoint = torch.load(checkpoint_path, map_location=self.device, weights_only=False)\n",
        "        model.load_state_dict(checkpoint['model_state_dict'])\n",
        "        model.eval()\n",
        "        return model, checkpoint\n",
        "\n",
        "    def evaluate_cnn(self, model_path, test_dataset):\n",
        "        print(\"\\n=== Evaluating CNN Nowcasting Model ===\")\n",
        "        model, checkpoint = self.load_model(SolarCNNRegression, model_path)\n",
        "        test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False, num_workers=2 )\n",
        "        predictions, targets = [], []\n",
        "        with torch.no_grad():\n",
        "            for images, batch_targets in test_loader:\n",
        "                images, batch_targets = images.to(self.device), batch_targets.to(self.device)\n",
        "                outputs = model(images)\n",
        "                predictions.extend(outputs.squeeze().cpu().numpy())\n",
        "                targets.extend(batch_targets.cpu().numpy())\n",
        "\n",
        "        predictions = np.array(predictions)\n",
        "        targets = np.array(targets)\n",
        "\n",
        "        mse = mean_squared_error(targets, predictions)\n",
        "        rmse = np.sqrt(mse)\n",
        "        mae = mean_absolute_error(targets, predictions)\n",
        "\n",
        "        self.results['cnn'] = {\n",
        "            'rmse': rmse,\n",
        "            'mae': mae,\n",
        "            'predictions': predictions.tolist(),\n",
        "            'targets': targets.tolist(),\n",
        "            'num_samples': len(predictions)\n",
        "        }\n",
        "\n",
        "        print(f\"CNN Results:\")\n",
        "        print(f\"  RMSE: {rmse:.2f} W/m²\")\n",
        "        print(f\"  MAE: {mae:.2f} W/m²\")\n",
        "        print(f\"  Samples: {len(predictions)}\")\n",
        "\n",
        "        return rmse, mae, predictions, targets\n",
        "\n",
        "    def evaluate_lstm(self, model_path, test_dataset):\n",
        "        print(\"\\n=== Evaluating LSTM Forecasting Model ===\")\n",
        "        checkpoint = torch.load(model_path, map_location=self.device, weights_only=False)\n",
        "        config = checkpoint.get('config', {})\n",
        "        model = SolarLSTMForecasting(\n",
        "            input_size=1,\n",
        "            hidden_size=config.get('lstm_hidden_size', 128),\n",
        "            num_layers=config.get('lstm_num_layers', 2),\n",
        "            output_size=config.get('forecast_horizon', 4),\n",
        "            dropout=config.get('dropout', 0.2)\n",
        "        ).to(self.device)\n",
        "\n",
        "        safe_load_checkpoint(model, model_path, self.device)\n",
        "        model.eval()\n",
        "        test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False, num_workers=2)\n",
        "        all_predictions, all_targets = [], []\n",
        "        with torch.no_grad():\n",
        "            for sequences, targets in test_loader:\n",
        "                sequences, targets = sequences.to(self.device), targets.to(self.device)\n",
        "                outputs = model(sequences)\n",
        "                all_predictions.append(outputs.cpu().numpy())\n",
        "                all_targets.append(targets.cpu().numpy())\n",
        "\n",
        "        predictions = np.concatenate(all_predictions, axis=0)\n",
        "        targets = np.concatenate(all_targets, axis=0)\n",
        "\n",
        "        overall_rmse = np.sqrt(mean_squared_error(targets.flatten(), predictions.flatten()))\n",
        "        overall_mae = mean_absolute_error(targets.flatten(), predictions.flatten())\n",
        "\n",
        "        forecast_step_metrics = []\n",
        "        if predictions.shape[1] > 0:\n",
        "            forecast_horizon = predictions.shape[1]\n",
        "            for step in range(forecast_horizon):\n",
        "                step_rmse = np.sqrt(mean_squared_error(targets[:, step], predictions[:, step]))\n",
        "                step_mae = mean_absolute_error(targets[:, step], predictions[:, step])\n",
        "                forecast_step_metrics.append({\n",
        "                    'step': step + 1,\n",
        "                    'rmse': step_rmse,\n",
        "                    'mae': step_mae\n",
        "                })\n",
        "\n",
        "        print(\"\\n=== Overall Metrics ===\")\n",
        "        print(f\"RMSE: {overall_rmse:.4f}\")\n",
        "        print(f\"MAE : {overall_mae:.4f}\")\n",
        "\n",
        "        self.results['lstm'] = {\n",
        "            'overall_rmse': overall_rmse,\n",
        "            'overall_mae': overall_mae,\n",
        "            'predictions': predictions.tolist(),\n",
        "            'targets': targets.tolist(),\n",
        "            'num_samples': len(predictions),\n",
        "            'step_metrics': forecast_step_metrics # Add step metrics\n",
        "        }\n",
        "\n",
        "        return overall_rmse, overall_mae, predictions, targets\n",
        "\n",
        "    def evaluate_hybrid(self, model_path, test_dataset):\n",
        "        print(\"\\n=== Evaluating Hybrid CNN-LSTM Model ===\")\n",
        "        checkpoint = torch.load(model_path, map_location=self.device, weights_only=False)\n",
        "        config = checkpoint.get('config', {})\n",
        "        model, _ = self.load_model(\n",
        "            HybridCNNLSTM,\n",
        "            model_path,\n",
        "            sequence_length=config.get('sequence_length', 20),\n",
        "            lstm_hidden_size=config.get('lstm_hidden_size', 128),\n",
        "            forecast_horizon=config.get('forecast_horizon', 4)\n",
        "        )\n",
        "\n",
        "        test_loader = DataLoader(test_dataset, batch_size=8, shuffle=False, num_workers=2)\n",
        "        all_nowcast_pred, all_nowcast_target, all_forecast_pred, all_forecast_target = [], [], [], []\n",
        "        with torch.no_grad():\n",
        "            for image_sequences, historical_irradiance, future_irradiance in test_loader:\n",
        "                image_sequences = image_sequences.to(self.device)\n",
        "                historical_irradiance = historical_irradiance.to(self.device)\n",
        "                future_irradiance = future_irradiance.to(self.device)\n",
        "                nowcasts, forecasts = model(image_sequences)\n",
        "                all_nowcast_pred.append(nowcasts.squeeze(-1).cpu().numpy())\n",
        "                all_nowcast_target.append(historical_irradiance.squeeze(-1).cpu().numpy())\n",
        "                all_forecast_pred.append(forecasts.cpu().numpy())\n",
        "                all_forecast_target.append(future_irradiance.cpu().numpy())\n",
        "\n",
        "        nowcast_pred = np.concatenate(all_nowcast_pred, axis=0)\n",
        "        nowcast_target = np.concatenate(all_nowcast_target, axis=0)\n",
        "        forecast_pred = np.concatenate(all_forecast_pred, axis=0)\n",
        "        forecast_target = np.concatenate(all_forecast_target, axis=0)\n",
        "\n",
        "        nowcast_rmse = np.sqrt(mean_squared_error(nowcast_target.flatten(), nowcast_pred.flatten()))\n",
        "        nowcast_mae = mean_absolute_error(nowcast_target.flatten(), nowcast_pred.flatten())\n",
        "        forecast_rmse = np.sqrt(mean_squared_error(forecast_target.flatten(), forecast_pred.flatten()))\n",
        "        forecast_mae = mean_absolute_error(forecast_target.flatten(), forecast_pred.flatten())\n",
        "\n",
        "        forecast_step_metrics = []\n",
        "        forecast_horizon = forecast_pred.shape[1]\n",
        "        for step in range(forecast_horizon):\n",
        "            step_rmse = np.sqrt(mean_squared_error(forecast_target[:, step], forecast_pred[:, step]))\n",
        "            step_mae = mean_absolute_error(forecast_target[:, step], forecast_pred[:, step])\n",
        "            forecast_step_metrics.append({\n",
        "                'step': step + 1,\n",
        "                'rmse': step_rmse,\n",
        "                'mae': step_mae\n",
        "            })\n",
        "\n",
        "        self.results['hybrid'] = {\n",
        "            'nowcast_rmse': nowcast_rmse,\n",
        "            'nowcast_mae': nowcast_mae,\n",
        "            'forecast_rmse': forecast_rmse,\n",
        "            'forecast_mae': forecast_mae,\n",
        "            'forecast_step_metrics': forecast_step_metrics,\n",
        "            'num_samples': len(forecast_pred)\n",
        "        }\n",
        "\n",
        "        print(f\"Hybrid Results:\")\n",
        "        print(f\"  Nowcast RMSE: {nowcast_rmse:.2f} W/m²\")\n",
        "        print(f\"  Nowcast MAE: {nowcast_mae:.2f} W/m²\")\n",
        "        print(f\"  Forecast RMSE: {forecast_rmse:.2f} W/m²\")\n",
        "        print(f\"  Forecast MAE: {forecast_mae:.2f} W/m²\")\n",
        "        print(f\"  Samples: {len(forecast_pred)}\")\n",
        "\n",
        "        return (nowcast_rmse, nowcast_mae, forecast_rmse, forecast_mae,\n",
        "                forecast_step_metrics, nowcast_pred, forecast_pred)\n",
        "\n",
        "\n",
        "    def plot_results(self, save_dir='evaluation_plots'):\n",
        "        \"\"\"Create visualization plots\"\"\"\n",
        "        os.makedirs(save_dir, exist_ok=True)\n",
        "\n",
        "        # CNN scatter plot\n",
        "        if 'cnn' in self.results:\n",
        "            plt.figure(figsize=(10, 8))\n",
        "\n",
        "            targets = np.array(self.results['cnn']['targets'])\n",
        "            predictions = np.array(self.results['cnn']['predictions'])\n",
        "\n",
        "            plt.subplot(2, 2, 1)\n",
        "            plt.scatter(targets, predictions, alpha=0.6, s=20)\n",
        "            plt.plot([targets.min(), targets.max()], [targets.min(), targets.max()], 'r--', lw=2)\n",
        "            plt.xlabel('Actual Irradiance (W/m²)')\n",
        "            plt.ylabel('Predicted Irradiance (W/m²)')\n",
        "            plt.title(f'CNN Nowcasting (RMSE: {self.results[\"cnn\"][\"rmse\"]:.2f} W/m²)')\n",
        "            plt.grid(True, alpha=0.3)\n",
        "\n",
        "            # Residuals plot\n",
        "            plt.subplot(2, 2, 2)\n",
        "            residuals = predictions - targets\n",
        "            plt.scatter(targets, residuals, alpha=0.6, s=20)\n",
        "            plt.axhline(y=0, color='r', linestyle='--')\n",
        "            plt.xlabel('Actual Irradiance (W/m²)')\n",
        "            plt.ylabel('Residuals (W/m²)')\n",
        "            plt.title('CNN Residuals')\n",
        "            plt.grid(True, alpha=0.3)\n",
        "\n",
        "            plt.tight_layout()\n",
        "            plt.savefig(f'{save_dir}/cnn_evaluation.png', dpi=300, bbox_inches='tight')\n",
        "            plt.show()\n",
        "            plt.close()\n",
        "\n",
        "        # LSTM overall performance\n",
        "        if 'lstm' in self.results:\n",
        "            overall_rmse = self.results['lstm']['overall_rmse']\n",
        "            overall_mae = self.results['lstm']['overall_mae']\n",
        "\n",
        "            plt.figure(figsize=(8, 6))\n",
        "            bar_labels = ['RMSE', 'MAE']\n",
        "            error_values = [overall_rmse, overall_mae]\n",
        "\n",
        "            plt.bar(bar_labels, error_values, color=['skyblue', 'lightcoral'], alpha=0.7)\n",
        "            plt.ylabel('Error (W/m²)')\n",
        "            plt.title('LSTM Overall Performance')\n",
        "            plt.grid(True, alpha=0.3, axis='y')\n",
        "\n",
        "            # Add value labels on bars\n",
        "            for i, val in enumerate(error_values):\n",
        "                plt.text(i, val + 1, f'{val:.2f}', ha='center', va='bottom')\n",
        "\n",
        "            plt.tight_layout()\n",
        "            plt.savefig(f'{save_dir}/lstm_overall_evaluation.png', dpi=300, bbox_inches='tight')\n",
        "            plt.show()\n",
        "            plt.close()\n",
        "\n",
        "\n",
        "        # Model comparison\n",
        "        if len(self.results) > 1:\n",
        "            plt.figure(figsize=(12, 8))\n",
        "\n",
        "            models = []\n",
        "            rmse_values = []\n",
        "            mae_values = []\n",
        "\n",
        "            if 'cnn' in self.results:\n",
        "                models.append('CNN\\nNowcasting')\n",
        "                rmse_values.append(self.results['cnn']['rmse'])\n",
        "                mae_values.append(self.results['cnn']['mae'])\n",
        "\n",
        "            if 'lstm' in self.results:\n",
        "                models.append('LSTM\\nForecasting')\n",
        "                rmse_values.append(self.results['lstm']['overall_rmse'])\n",
        "                mae_values.append(self.results['lstm']['overall_mae'])\n",
        "\n",
        "            if 'hybrid' in self.results:\n",
        "                models.append('Hybrid\\nNowcast')\n",
        "                rmse_values.append(self.results['hybrid']['nowcast_rmse'])\n",
        "                mae_values.append(self.results['hybrid']['nowcast_mae'])\n",
        "\n",
        "                models.append('Hybrid\\nForecast')\n",
        "                rmse_values.append(self.results['hybrid']['forecast_rmse'])\n",
        "                mae_values.append(self.results['hybrid']['forecast_mae'])\n",
        "\n",
        "            x = np.arange(len(models))\n",
        "            width = 0.35\n",
        "\n",
        "            plt.subplot(1, 1, 1)\n",
        "            plt.bar(x - width/2, rmse_values, width, label='RMSE', color='skyblue', alpha=0.8)\n",
        "            plt.bar(x + width/2, mae_values, width, label='MAE', color='lightcoral', alpha=0.8)\n",
        "\n",
        "            plt.xlabel('Models')\n",
        "            plt.ylabel('Error (W/m²)')\n",
        "            plt.title('Model Performance Comparison')\n",
        "            plt.xticks(x, models)\n",
        "            plt.legend()\n",
        "            plt.grid(True, alpha=0.3)\n",
        "\n",
        "            # Add value labels on bars\n",
        "            for i, (rmse, mae) in enumerate(zip(rmse_values, mae_values)):\n",
        "                plt.text(i - width/2, rmse + 1, f'{rmse:.1f}', ha='center', va='bottom')\n",
        "                plt.text(i + width/2, mae + 1, f'{mae:.1f}', ha='center', va='bottom')\n",
        "\n",
        "            plt.tight_layout()\n",
        "            plt.savefig(f'{save_dir}/model_comparison.png', dpi=300, bbox_inches='tight')\n",
        "            plt.show()\n",
        "            plt.close()\n",
        "\n",
        "        print(f\"\\nPlots saved to {save_dir}/\")\n",
        "\n",
        "    def save_results(self, filename='evaluation_results.json'):\n",
        "        results_with_metadata = {\n",
        "            'evaluation_timestamp': datetime.now().isoformat(),\n",
        "            'device': str(self.device),\n",
        "            'results': self.results\n",
        "        }\n",
        "        with open(filename, 'w') as f:\n",
        "            json.dump(results_with_metadata, f, indent=2)\n",
        "        print(f\"\\nResults saved to {filename}\")\n",
        "\n",
        "    def generate_report(self, filename='evaluation_report.txt'):\n",
        "        with open(filename, 'w') as f:\n",
        "            f.write(\"=\"*80 + \"\\n\")\n",
        "            f.write(\"SOLAR IRRADIANCE FORECASTING - MODEL EVALUATION REPORT\\n\")\n",
        "            f.write(\"=\"*80 + \"\\n\")\n",
        "            f.write(f\"Generated: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\\n\")\n",
        "            f.write(f\"Device: {self.device}\\n\\n\")\n",
        "            if 'cnn' in self.results:\n",
        "                r = self.results['cnn']\n",
        "                f.write(\"CNN NOWCASTING MODEL\\n\")\n",
        "                f.write(\"-\"*30 + \"\\n\")\n",
        "                f.write(f\"RMSE: {r['rmse']:.2f} W/m²\\n\")\n",
        "                f.write(f\"MAE: {r['mae']:.2f} W/m²\\n\\n\")\n",
        "            if 'lstm' in self.results:\n",
        "                r = self.results['lstm']\n",
        "                f.write(\"LSTM FORECASTING MODEL\\n\")\n",
        "                f.write(\"-\"*30 + \"\\n\")\n",
        "                f.write(f\"RMSE: {r['overall_rmse']:.2f} W/m²\\n\")\n",
        "                f.write(f\"MAE: {r['overall_mae']:.2f} W/m²\\n\\n\")\n",
        "            if 'hybrid' in self.results:\n",
        "                r = self.results['hybrid']\n",
        "                f.write(\"HYBRID CNN-LSTM MODEL\\n\")\n",
        "                f.write(\"-\"*30 + \"\\n\")\n",
        "                f.write(f\"Nowcast RMSE: {r['nowcast_rmse']:.2f} W/m²\\n\")\n",
        "                f.write(f\"Nowcast MAE: {r['nowcast_mae']:.2f} W/m²\\n\")\n",
        "                f.write(f\"Forecast RMSE: {r['forecast_rmse']:.2f} W/m²\\n\")\n",
        "                f.write(f\"Forecast MAE: {r['forecast_mae']:.2f} W/m²\\n\\n\")\n",
        "        print(f\"Report saved to {filename}\")\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import json\n",
        "from datetime import datetime\n",
        "import torch.nn as nn\n",
        "import torch.serialization\n",
        "\n",
        "from cnn_model import SolarCNNRegression, SolarCNNWithFeatureExtraction\n",
        "from lstm_model import HybridCNNLSTM\n",
        "from solar_datasets import SolarIrradianceDataset, SolarTimeSeriesDataset, SolarSequenceDataset\n",
        "\n",
        "\n",
        "# ---------------------------\n",
        "# Dataset\n",
        "# ---------------------------\n",
        "class MultiDayTimeSeriesDataset(Dataset):\n",
        "    def __init__(self, irradiance_file, sequence_length=20, forecast_horizon=4, value_col_index=1):\n",
        "        df = pd.read_csv(irradiance_file)\n",
        "        vals = df.iloc[:, value_col_index].astype(np.float32).values\n",
        "        self.series = vals\n",
        "        self.seq_len = sequence_length\n",
        "        self.horizon = forecast_horizon\n",
        "        self.length = len(self.series) - self.seq_len - self.horizon + 1\n",
        "        if self.length < 1:\n",
        "            raise ValueError(\"Not enough data samples for given sequence_length + forecast_horizon.\")\n",
        "    def __len__(self):\n",
        "        return self.length\n",
        "    def __getitem__(self, idx):\n",
        "        seq = self.series[idx : idx + self.seq_len]\n",
        "        tgt = self.series[idx + self.seq_len : idx + self.seq_len + self.horizon]\n",
        "        seq = torch.tensor(seq, dtype=torch.float32).unsqueeze(-1)\n",
        "        tgt = torch.tensor(tgt, dtype=torch.float32)\n",
        "        return seq, tgt\n",
        "\n",
        "\n",
        "# ---------------------------\n",
        "# LSTM Model\n",
        "# ---------------------------\n",
        "class SolarLSTMForecasting(nn.Module):\n",
        "    def __init__(self, input_size=1, hidden_size=128, num_layers=2, output_size=4, dropout=0.2):\n",
        "        super(SolarLSTMForecasting, self).__init__()\n",
        "        self.lstm = nn.LSTM(input_size=input_size,\n",
        "                            hidden_size=hidden_size,\n",
        "                            num_layers=num_layers,\n",
        "                            batch_first=True,\n",
        "                            dropout=dropout if num_layers > 1 else 0.0)\n",
        "        self.fc = nn.Linear(hidden_size, output_size)\n",
        "    def forward(self, x):\n",
        "        out, _ = self.lstm(x)\n",
        "        last = out[:, -1, :]\n",
        "        return self.fc(last)\n",
        "\n",
        "\n",
        "# ---------------------------\n",
        "# Safe checkpoint loader\n",
        "# ---------------------------\n",
        "def safe_load_checkpoint(model, model_path, device):\n",
        "    import torch.serialization\n",
        "    import numpy as np\n",
        "    try:\n",
        "        torch.serialization.add_safe_globals([np.core.multiarray.scalar, np.dtype, np.float64])\n",
        "    except Exception:\n",
        "        pass\n",
        "\n",
        "    ckpt = torch.load(model_path, map_location=device, weights_only=False)\n",
        "    if isinstance(ckpt, dict) and 'model_state_dict' in ckpt:\n",
        "        state_dict = ckpt['model_state_dict']\n",
        "    elif isinstance(ckpt, dict):\n",
        "        state_dict = ckpt\n",
        "    else:\n",
        "        raise RuntimeError(\"Unexpected checkpoint format.\")\n",
        "\n",
        "    model_dict = model.state_dict()\n",
        "    filtered = {}\n",
        "    skipped = []\n",
        "    for k, v in state_dict.items():\n",
        "        if k in model_dict:\n",
        "            if isinstance(v, torch.Tensor) and v.shape == model_dict[k].shape:\n",
        "                filtered[k] = v\n",
        "            else:\n",
        "                skipped.append((k, getattr(v, 'shape', None), model_dict[k].shape))\n",
        "    model_dict.update(filtered)\n",
        "    model.load_state_dict(model_dict)\n",
        "    if skipped:\n",
        "        print(\"Warning: some keys were skipped due to shape mismatch:\")\n",
        "        for item in skipped[:10]:\n",
        "            print(\"  \", item)\n",
        "    return ckpt\n",
        "\n",
        "\n",
        "# ---------------------------\n",
        "# Evaluation class\n",
        "# ---------------------------\n",
        "class ModelEvaluator:\n",
        "    def __init__(self, device=None):\n",
        "        self.device = device or torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "        print(f\"Using device: {self.device}\")\n",
        "        self.results = {}\n",
        "\n",
        "    def load_model(self, model_class, checkpoint_path, **kwargs):\n",
        "        model = model_class(**kwargs).to(self.device)\n",
        "        checkpoint = torch.load(checkpoint_path, map_location=self.device, weights_only=False)\n",
        "        model.load_state_dict(checkpoint['model_state_dict'])\n",
        "        model.eval()\n",
        "        return model, checkpoint\n",
        "\n",
        "    def evaluate_cnn(self, model_path, test_dataset):\n",
        "        print(\"\\n=== Evaluating CNN Nowcasting Model ===\")\n",
        "        model, checkpoint = self.load_model(EfficientNetRegression, model_path)\n",
        "        test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False, num_workers=2)\n",
        "        predictions, targets = [], []\n",
        "        with torch.no_grad():\n",
        "            for images, batch_targets in test_loader:\n",
        "                images, batch_targets = images.to(self.device), batch_targets.to(self.device)\n",
        "                outputs = model(images)\n",
        "                predictions.extend(outputs.squeeze().cpu().numpy())\n",
        "                targets.extend(batch_targets.cpu().numpy())\n",
        "\n",
        "        predictions = np.array(predictions)\n",
        "        targets = np.array(targets)\n",
        "\n",
        "        mse = mean_squared_error(targets, predictions)\n",
        "        rmse = np.sqrt(mse)\n",
        "        mae = mean_absolute_error(targets, predictions)\n",
        "\n",
        "        self.results['cnn'] = {\n",
        "            'rmse': rmse,\n",
        "            'mae': mae,\n",
        "            'predictions': predictions.tolist(),\n",
        "            'targets': targets.tolist(),\n",
        "            'num_samples': len(predictions)\n",
        "        }\n",
        "\n",
        "        print(f\"CNN Results:\")\n",
        "        print(f\"  RMSE: {rmse:.2f} W/m²\")\n",
        "        print(f\"  MAE: {mae:.2f} W/m²\")\n",
        "        print(f\"  Samples: {len(predictions)}\")\n",
        "\n",
        "        return rmse, mae, predictions, targets\n",
        "\n",
        "    def evaluate_model(self, model, model_name, test_dataset, batch_size=16):\n",
        "        \"\"\"Evaluate a single model on test data\"\"\"\n",
        "        print(f\"\\n=== Evaluating {model_name} Model ===\")\n",
        "        test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
        "        preds, targets = [], []\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for images, labels in test_loader:\n",
        "                images, labels = images.to(self.device), labels.to(self.device)\n",
        "                outputs = model(images).squeeze()\n",
        "                preds.extend(outputs.cpu().numpy())\n",
        "                targets.extend(labels.cpu().numpy())\n",
        "\n",
        "        preds, targets = np.array(preds), np.array(targets)\n",
        "        mse = mean_squared_error(targets, preds)\n",
        "        rmse = np.sqrt(mse)\n",
        "        mae = mean_absolute_error(targets, preds)\n",
        "\n",
        "        self.results[model_name] = {\n",
        "            \"RMSE\": rmse,\n",
        "            \"MAE\": mae,\n",
        "            \"Samples\": len(preds),\n",
        "            \"Predictions\": preds.tolist(),\n",
        "            \"Targets\": targets.tolist(),\n",
        "        }\n",
        "\n",
        "        print(f\"RMSE: {rmse:.2f} | MAE: {mae:.2f} | Samples: {len(preds)}\")\n",
        "        print(\"------------------------------------------------------------\")\n",
        "        return preds, targets\n",
        "\n",
        "    def evaluate_lstm(self, model_path, test_dataset):\n",
        "        print(\"\\n=== Evaluating LSTM Forecasting Model ===\")\n",
        "        checkpoint = torch.load(model_path, map_location=self.device, weights_only=False)\n",
        "        config = checkpoint.get('config', {})\n",
        "        model = SolarLSTMForecasting(\n",
        "            input_size=1,\n",
        "            hidden_size=config.get('lstm_hidden_size', 128),\n",
        "            num_layers=config.get('lstm_num_layers', 2),\n",
        "            output_size=config.get('forecast_horizon', 4),\n",
        "            dropout=config.get('dropout', 0.2)\n",
        "        ).to(self.device)\n",
        "\n",
        "        safe_load_checkpoint(model, model_path, self.device)\n",
        "        model.eval()\n",
        "        test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False, num_workers=2)\n",
        "        all_predictions, all_targets = [], []\n",
        "        with torch.no_grad():\n",
        "            for sequences, targets in test_loader:\n",
        "                sequences, targets = sequences.to(self.device), targets.to(self.device)\n",
        "                outputs = model(sequences)\n",
        "                all_predictions.append(outputs.cpu().numpy())\n",
        "                all_targets.append(targets.cpu().numpy())\n",
        "\n",
        "        predictions = np.concatenate(all_predictions, axis=0)\n",
        "        targets = np.concatenate(all_targets, axis=0)\n",
        "\n",
        "        overall_rmse = np.sqrt(mean_squared_error(targets.flatten(), predictions.flatten()))\n",
        "        overall_mae = mean_absolute_error(targets.flatten(), predictions.flatten())\n",
        "\n",
        "        forecast_step_metrics = []\n",
        "        if predictions.shape[1] > 0:\n",
        "            forecast_horizon = predictions.shape[1]\n",
        "            for step in range(forecast_horizon):\n",
        "                step_rmse = np.sqrt(mean_squared_error(targets[:, step], predictions[:, step]))\n",
        "                step_mae = mean_absolute_error(targets[:, step], predictions[:, step])\n",
        "                forecast_step_metrics.append({\n",
        "                    'step': step + 1,\n",
        "                    'rmse': step_rmse,\n",
        "                    'mae': step_mae\n",
        "                })\n",
        "\n",
        "        print(\"\\n=== Overall Metrics ===\")\n",
        "        print(f\"RMSE: {overall_rmse:.4f}\")\n",
        "        print(f\"MAE : {overall_mae:.4f}\")\n",
        "\n",
        "        self.results['lstm'] = {\n",
        "            'overall_rmse': overall_rmse,\n",
        "            'overall_mae': overall_mae,\n",
        "            'predictions': predictions.tolist(),\n",
        "            'targets': targets.tolist(),\n",
        "            'num_samples': len(predictions),\n",
        "            'step_metrics': forecast_step_metrics # Add step metrics\n",
        "        }\n",
        "\n",
        "        return overall_rmse, overall_mae, predictions, targets\n",
        "\n",
        "    def evaluate_hybrid(self, model_path, test_dataset):\n",
        "        print(\"\\n=== Evaluating Hybrid CNN-LSTM Model ===\")\n",
        "        checkpoint = torch.load(model_path, map_location=self.device, weights_only=False)\n",
        "        config = checkpoint.get('config', {})\n",
        "        model, _ = self.load_model(\n",
        "            HybridCNNLSTM,\n",
        "            model_path,\n",
        "            sequence_length=config.get('sequence_length', 20),\n",
        "            lstm_hidden_size=config.get('lstm_hidden_size', 128),\n",
        "            forecast_horizon=config.get('forecast_horizon', 4)\n",
        "        )\n",
        "\n",
        "        test_loader = DataLoader(test_dataset, batch_size=8, shuffle=False, num_workers=2)\n",
        "        all_nowcast_pred, all_nowcast_target, all_forecast_pred, all_forecast_target = [], [], [], []\n",
        "        with torch.no_grad():\n",
        "            for image_sequences, historical_irradiance, future_irradiance in test_loader:\n",
        "                image_sequences = image_sequences.to(self.device)\n",
        "                historical_irradiance = historical_irradiance.to(self.device)\n",
        "                future_irradiance = future_irradiance.to(self.device)\n",
        "                nowcasts, forecasts = model(image_sequences)\n",
        "                all_nowcast_pred.append(nowcasts.squeeze(-1).cpu().numpy())\n",
        "                all_nowcast_target.append(historical_irradiance.squeeze(-1).cpu().numpy())\n",
        "                all_forecast_pred.append(forecasts.cpu().numpy())\n",
        "                all_forecast_target.append(future_irradiance.cpu().numpy())\n",
        "\n",
        "        nowcast_pred = np.concatenate(all_nowcast_pred, axis=0)\n",
        "        nowcast_target = np.concatenate(all_nowcast_target, axis=0)\n",
        "        forecast_pred = np.concatenate(all_forecast_pred, axis=0)\n",
        "        forecast_target = np.concatenate(all_forecast_target, axis=0)\n",
        "\n",
        "        nowcast_rmse = np.sqrt(mean_squared_error(nowcast_target.flatten(), nowcast_pred.flatten()))\n",
        "        nowcast_mae = mean_absolute_error(nowcast_target.flatten(), nowcast_pred.flatten())\n",
        "        forecast_rmse = np.sqrt(mean_squared_error(forecast_target.flatten(), forecast_pred.flatten()))\n",
        "        forecast_mae = mean_absolute_error(forecast_target.flatten(), forecast_pred.flatten())\n",
        "\n",
        "        forecast_step_metrics = []\n",
        "        forecast_horizon = forecast_pred.shape[1]\n",
        "        for step in range(forecast_horizon):\n",
        "            step_rmse = np.sqrt(mean_squared_error(forecast_target[:, step], forecast_pred[:, step]))\n",
        "            step_mae = mean_absolute_error(forecast_target[:, step], forecast_pred[:, step])\n",
        "            forecast_step_metrics.append({\n",
        "                'step': step + 1,\n",
        "                'rmse': step_rmse,\n",
        "                'mae': step_mae\n",
        "            })\n",
        "\n",
        "        self.results['hybrid'] = {\n",
        "            'nowcast_rmse': nowcast_rmse,\n",
        "            'nowcast_mae': nowcast_mae,\n",
        "            'forecast_rmse': forecast_rmse,\n",
        "            'forecast_mae': forecast_mae,\n",
        "            'forecast_step_metrics': forecast_step_metrics,\n",
        "            'num_samples': len(forecast_pred)\n",
        "        }\n",
        "\n",
        "        print(f\"Hybrid Results:\")\n",
        "        print(f\"  Nowcast RMSE: {nowcast_rmse:.2f} W/m²\")\n",
        "        print(f\"  Nowcast MAE: {nowcast_mae:.2f} W/m²\")\n",
        "        print(f\"  Forecast RMSE: {forecast_rmse:.2f} W/m²\")\n",
        "        print(f\"  Forecast MAE: {forecast_mae:.2f} W/m²\")\n",
        "        print(f\"  Samples: {len(forecast_pred)}\")\n",
        "\n",
        "        return (nowcast_rmse, nowcast_mae, forecast_rmse, forecast_mae,\n",
        "                forecast_step_metrics, nowcast_pred, forecast_pred)\n",
        "\n",
        "\n",
        "    def plot_results(self, save_dir='evaluation_plots'):\n",
        "        \"\"\"Create visualization plots\"\"\"\n",
        "        os.makedirs(save_dir, exist_ok=True)\n",
        "\n",
        "        # CNN scatter plot\n",
        "        if 'cnn' in self.results:\n",
        "            plt.figure(figsize=(10, 8))\n",
        "\n",
        "            targets = np.array(self.results['cnn']['targets'])\n",
        "            predictions = np.array(self.results['cnn']['predictions'])\n",
        "\n",
        "            plt.subplot(2, 2, 1)\n",
        "            plt.scatter(targets, predictions, alpha=0.6, s=20)\n",
        "            plt.plot([targets.min(), targets.max()], [targets.min(), targets.max()], 'r--', lw=2)\n",
        "            plt.xlabel('Actual Irradiance (W/m²)')\n",
        "            plt.ylabel('Predicted Irradiance (W/m²)')\n",
        "            plt.title(f'CNN Nowcasting (RMSE: {self.results[\"cnn\"][\"rmse\"]:.2f} W/m²)')\n",
        "            plt.grid(True, alpha=0.3)\n",
        "\n",
        "            # Residuals plot\n",
        "            plt.subplot(2, 2, 2)\n",
        "            residuals = predictions - targets\n",
        "            plt.scatter(targets, residuals, alpha=0.6, s=20)\n",
        "            plt.axhline(y=0, color='r', linestyle='--')\n",
        "            plt.xlabel('Actual Irradiance (W/m²)')\n",
        "            plt.ylabel('Residuals (W/m²)')\n",
        "            plt.title('CNN Residuals')\n",
        "            plt.grid(True, alpha=0.3)\n",
        "\n",
        "            plt.tight_layout()\n",
        "            plt.savefig(f'{save_dir}/cnn_evaluation.png', dpi=300, bbox_inches='tight')\n",
        "            plt.close()\n",
        "\n",
        "        # LSTM overall performance\n",
        "        if 'lstm' in self.results:\n",
        "            overall_rmse = self.results['lstm']['overall_rmse']\n",
        "            overall_mae = self.results['lstm']['overall_mae']\n",
        "\n",
        "            plt.figure(figsize=(8, 6))\n",
        "            bar_labels = ['RMSE', 'MAE']\n",
        "            error_values = [overall_rmse, overall_mae]\n",
        "\n",
        "            plt.bar(bar_labels, error_values, color=['skyblue', 'lightcoral'], alpha=0.7)\n",
        "            plt.ylabel('Error (W/m²)')\n",
        "            plt.title('LSTM Overall Performance')\n",
        "            plt.grid(True, alpha=0.3, axis='y')\n",
        "\n",
        "            # Add value labels on bars\n",
        "            for i, val in enumerate(error_values):\n",
        "                plt.text(i, val + 1, f'{val:.2f}', ha='center', va='bottom')\n",
        "\n",
        "            plt.tight_layout()\n",
        "            plt.savefig(f'{save_dir}/lstm_overall_evaluation.png', dpi=300, bbox_inches='tight')\n",
        "            plt.close()\n",
        "\n",
        "\n",
        "        # Model comparison\n",
        "        if len(self.results) > 1:\n",
        "            plt.figure(figsize=(12, 8))\n",
        "\n",
        "            models = []\n",
        "            rmse_values = []\n",
        "            mae_values = []\n",
        "\n",
        "            if 'cnn' in self.results:\n",
        "                models.append('CNN\\nNowcasting')\n",
        "                rmse_values.append(self.results['cnn']['rmse'])\n",
        "                mae_values.append(self.results['cnn']['mae'])\n",
        "\n",
        "            if 'lstm' in self.results:\n",
        "                models.append('LSTM\\nForecasting')\n",
        "                rmse_values.append(self.results['lstm']['overall_rmse'])\n",
        "                mae_values.append(self.results['lstm']['overall_mae'])\n",
        "\n",
        "            if 'hybrid' in self.results:\n",
        "                models.append('Hybrid\\nNowcast')\n",
        "                rmse_values.append(self.results['hybrid']['nowcast_rmse'])\n",
        "                mae_values.append(self.results['hybrid']['nowcast_mae'])\n",
        "\n",
        "                models.append('Hybrid\\nForecast')\n",
        "                rmse_values.append(self.results['hybrid']['forecast_rmse'])\n",
        "                mae_values.append(self.results['hybrid']['forecast_mae'])\n",
        "\n",
        "            x = np.arange(len(models))\n",
        "            width = 0.35\n",
        "\n",
        "            plt.subplot(1, 1, 1)\n",
        "            plt.bar(x - width/2, rmse_values, width, label='RMSE', color='skyblue', alpha=0.8)\n",
        "            plt.bar(x + width/2, mae_values, width, label='MAE', color='lightcoral', alpha=0.8)\n",
        "\n",
        "            plt.xlabel('Models')\n",
        "            plt.ylabel('Error (W/m²)')\n",
        "            plt.title('Model Performance Comparison')\n",
        "            plt.xticks(x, models)\n",
        "            plt.legend()\n",
        "            plt.grid(True, alpha=0.3)\n",
        "\n",
        "            # Add value labels on bars\n",
        "            for i, (rmse, mae) in enumerate(zip(rmse_values, mae_values)):\n",
        "                plt.text(i - width/2, rmse + 1, f'{rmse:.1f}', ha='center', va='bottom')\n",
        "                plt.text(i + width/2, mae + 1, f'{mae:.1f}', ha='center', va='bottom')\n",
        "\n",
        "            plt.tight_layout()\n",
        "            plt.savefig(f'{save_dir}/model_comparison.png', dpi=300, bbox_inches='tight')\n",
        "            plt.close()\n",
        "\n",
        "        print(f\"\\nPlots saved to {save_dir}/\")\n",
        "\n",
        "    def save_results(self, filename='evaluation_results.json'):\n",
        "        results_with_metadata = {\n",
        "            'evaluation_timestamp': datetime.now().isoformat(),\n",
        "            'device': str(self.device),\n",
        "            'results': self.results\n",
        "        }\n",
        "        with open(filename, 'w') as f:\n",
        "            json.dump(results_with_metadata, f, indent=2)\n",
        "        print(f\"\\nResults saved to {filename}\")\n",
        "\n",
        "    def generate_report(self, filename='evaluation_report.txt'):\n",
        "        with open(filename, 'w') as f:\n",
        "            f.write(\"=\"*80 + \"\\n\")\n",
        "            f.write(\"SOLAR IRRADIANCE FORECASTING - MODEL EVALUATION REPORT\\n\")\n",
        "            f.write(\"=\"*80 + \"\\n\")\n",
        "            f.write(f\"Generated: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\\n\")\n",
        "            f.write(f\"Device: {self.device}\\n\\n\")\n",
        "            if 'cnn' in self.results:\n",
        "                r = self.results['cnn']\n",
        "                f.write(\"CNN NOWCASTING MODEL\\n\")\n",
        "                f.write(\"-\"*30 + \"\\n\")\n",
        "                f.write(f\"RMSE: {r['rmse']:.2f} W/m²\\n\")\n",
        "                f.write(f\"MAE: {r['mae']:.2f} W/m²\\n\\n\")\n",
        "            if 'lstm' in self.results:\n",
        "                r = self.results['lstm']\n",
        "                f.write(\"LSTM FORECASTING MODEL\\n\")\n",
        "                f.write(\"-\"*30 + \"\\n\")\n",
        "                f.write(f\"RMSE: {r['overall_rmse']:.2f} W/m²\\n\")\n",
        "                f.write(f\"MAE: {r['overall_mae']:.2f} W/m²\\n\\n\")\n",
        "            if 'hybrid' in self.results:\n",
        "                r = self.results['hybrid']\n",
        "                f.write(\"HYBRID CNN-LSTM MODEL\\n\")\n",
        "                f.write(\"-\"*30 + \"\\n\")\n",
        "                f.write(f\"Nowcast RMSE: {r['nowcast_rmse']:.2f} W/m²\\n\")\n",
        "                f.write(f\"Nowcast MAE: {r['nowcast_mae']:.2f} W/m²\\n\")\n",
        "                f.write(f\"Forecast RMSE: {r['forecast_rmse']:.2f} W/m²\\n\")\n",
        "                f.write(f\"Forecast MAE: {r['forecast_mae']:.2f} W/m²\\n\\n\")\n",
        "        print(f\"Report saved to {filename}\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "zw4XIxNOVCWf"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import json\n",
        "from datetime import datetime\n",
        "import torch.nn as nn\n",
        "import torch.serialization\n",
        "\n",
        "from cnn_model import SolarCNNRegression, SolarCNNWithFeatureExtraction\n",
        "from lstm_model import HybridCNNLSTM\n",
        "from solar_datasets import SolarIrradianceDataset, SolarTimeSeriesDataset, SolarSequenceDataset\n",
        "\n",
        "\n",
        "# ---------------------------\n",
        "# Dataset\n",
        "# ---------------------------\n",
        "class MultiDayTimeSeriesDataset(Dataset):\n",
        "    def __init__(self, irradiance_file, sequence_length=20, forecast_horizon=4, value_col_index=1):\n",
        "        df = pd.read_csv(irradiance_file)\n",
        "        vals = df.iloc[:, value_col_index].astype(np.float32).values\n",
        "        self.series = vals\n",
        "        self.seq_len = sequence_length\n",
        "        self.horizon = forecast_horizon\n",
        "        self.length = len(self.series) - self.seq_len - self.horizon + 1\n",
        "        if self.length < 1:\n",
        "            raise ValueError(\"Not enough data samples for given sequence_length + forecast_horizon.\")\n",
        "    def __len__(self):\n",
        "        return self.length\n",
        "    def __getitem__(self, idx):\n",
        "        seq = self.series[idx : idx + self.seq_len]\n",
        "        tgt = self.series[idx + self.seq_len : idx + self.seq_len + self.horizon]\n",
        "        seq = torch.tensor(seq, dtype=torch.float32).unsqueeze(-1)\n",
        "        tgt = torch.tensor(tgt, dtype=torch.float32)\n",
        "        return seq, tgt\n",
        "\n",
        "\n",
        "# ---------------------------\n",
        "# LSTM Model\n",
        "# ---------------------------\n",
        "class SolarLSTMForecasting(nn.Module):\n",
        "    def __init__(self, input_size=1, hidden_size=128, num_layers=2, output_size=4, dropout=0.2):\n",
        "        super(SolarLSTMForecasting, self).__init__()\n",
        "        self.lstm = nn.LSTM(input_size=input_size,\n",
        "                            hidden_size=hidden_size,\n",
        "                            num_layers=num_layers,\n",
        "                            batch_first=True,\n",
        "                            dropout=dropout if num_layers > 1 else 0.0)\n",
        "        self.fc = nn.Linear(hidden_size, output_size)\n",
        "    def forward(self, x):\n",
        "        out, _ = self.lstm(x)\n",
        "        last = out[:, -1, :]\n",
        "        return self.fc(last)\n",
        "\n",
        "\n",
        "# ---------------------------\n",
        "# Safe checkpoint loader\n",
        "# ---------------------------\n",
        "def safe_load_checkpoint(model, model_path, device):\n",
        "    import torch.serialization\n",
        "    import numpy as np\n",
        "    try:\n",
        "        torch.serialization.add_safe_globals([np.core.multiarray.scalar, np.dtype, np.float64])\n",
        "    except Exception:\n",
        "        pass\n",
        "\n",
        "    ckpt = torch.load(model_path, map_location=device, weights_only=False)\n",
        "    if isinstance(ckpt, dict) and 'model_state_dict' in ckpt:\n",
        "        state_dict = ckpt['model_state_dict']\n",
        "    elif isinstance(ckpt, dict):\n",
        "        state_dict = ckpt\n",
        "    else:\n",
        "        raise RuntimeError(\"Unexpected checkpoint format.\")\n",
        "\n",
        "    model_dict = model.state_dict()\n",
        "    filtered = {}\n",
        "    skipped = []\n",
        "    for k, v in state_dict.items():\n",
        "        if k in model_dict:\n",
        "            if isinstance(v, torch.Tensor) and v.shape == model_dict[k].shape:\n",
        "                filtered[k] = v\n",
        "            else:\n",
        "                skipped.append((k, getattr(v, 'shape', None), model_dict[k].shape))\n",
        "    model_dict.update(filtered)\n",
        "    model.load_state_dict(model_dict)\n",
        "    if skipped:\n",
        "        print(\"Warning: some keys were skipped due to shape mismatch:\")\n",
        "        for item in skipped[:10]:\n",
        "            print(\"  \", item)\n",
        "    return ckpt\n",
        "\n",
        "\n",
        "# ---------------------------\n",
        "# Evaluation class\n",
        "# ---------------------------\n",
        "class ModelEvaluator:\n",
        "    def __init__(self, device=None):\n",
        "        self.device = device or torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "        print(f\"Using device: {self.device}\")\n",
        "        self.results = {}\n",
        "\n",
        "    def load_model(self, model_class, checkpoint_path, **kwargs):\n",
        "        model = model_class(**kwargs).to(self.device)\n",
        "        checkpoint = torch.load(checkpoint_path, map_location=self.device, weights_only=False)\n",
        "        model.load_state_dict(checkpoint['model_state_dict'])\n",
        "        model.eval()\n",
        "        return model, checkpoint\n",
        "\n",
        "    def evaluate_cnn(self, model_path, test_dataset):\n",
        "        print(\"\\n=== Evaluating CNN Nowcasting Model ===\")\n",
        "        model, checkpoint = self.load_model(SolarCNNRegression, model_path)\n",
        "        test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False, num_workers=2)\n",
        "        predictions, targets = [], []\n",
        "        with torch.no_grad():\n",
        "            for images, batch_targets in test_loader:\n",
        "                images, batch_targets = images.to(self.device), batch_targets.to(self.device)\n",
        "                outputs = model(images)\n",
        "                predictions.extend(outputs.squeeze().cpu().numpy())\n",
        "                targets.extend(batch_targets.cpu().numpy())\n",
        "\n",
        "        predictions = np.array(predictions)\n",
        "        targets = np.array(targets)\n",
        "\n",
        "        mse = mean_squared_error(targets, predictions)\n",
        "        rmse = np.sqrt(mse)\n",
        "        mae = mean_absolute_error(targets, predictions)\n",
        "\n",
        "        self.results['cnn'] = {\n",
        "            'rmse': rmse,\n",
        "            'mae': mae,\n",
        "            'predictions': predictions.tolist(),\n",
        "            'targets': targets.tolist(),\n",
        "            'num_samples': len(predictions)\n",
        "        }\n",
        "\n",
        "        print(f\"CNN Results:\")\n",
        "        print(f\"  RMSE: {rmse:.2f} W/m²\")\n",
        "        print(f\"  MAE: {mae:.2f} W/m²\")\n",
        "        print(f\"  Samples: {len(predictions)}\")\n",
        "\n",
        "        return rmse, mae, predictions, targets\n",
        "\n",
        "    def evaluate_lstm(self, model_path, test_dataset):\n",
        "        print(\"\\n=== Evaluating LSTM Forecasting Model ===\")\n",
        "        checkpoint = torch.load(model_path, map_location=self.device, weights_only=False)\n",
        "        config = checkpoint.get('config', {})\n",
        "        model = SolarLSTMForecasting(\n",
        "            input_size=1,\n",
        "            hidden_size=config.get('lstm_hidden_size', 128),\n",
        "            num_layers=config.get('lstm_num_layers', 2),\n",
        "            output_size=config.get('forecast_horizon', 4),\n",
        "            dropout=config.get('dropout', 0.2)\n",
        "        ).to(self.device)\n",
        "\n",
        "        safe_load_checkpoint(model, model_path, self.device)\n",
        "        model.eval()\n",
        "        test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False, num_workers=2)\n",
        "        all_predictions, all_targets = [], []\n",
        "        with torch.no_grad():\n",
        "            for sequences, targets in test_loader:\n",
        "                sequences, targets = sequences.to(self.device), targets.to(self.device)\n",
        "                outputs = model(sequences)\n",
        "                all_predictions.append(outputs.cpu().numpy())\n",
        "                all_targets.append(targets.cpu().numpy())\n",
        "\n",
        "        predictions = np.concatenate(all_predictions, axis=0)\n",
        "        targets = np.concatenate(all_targets, axis=0)\n",
        "\n",
        "        overall_rmse = np.sqrt(mean_squared_error(targets.flatten(), predictions.flatten()))\n",
        "        overall_mae = mean_absolute_error(targets.flatten(), predictions.flatten())\n",
        "\n",
        "        forecast_step_metrics = []\n",
        "        if predictions.shape[1] > 0:\n",
        "            forecast_horizon = predictions.shape[1]\n",
        "            for step in range(forecast_horizon):\n",
        "                step_rmse = np.sqrt(mean_squared_error(targets[:, step], predictions[:, step]))\n",
        "                step_mae = mean_absolute_error(targets[:, step], predictions[:, step])\n",
        "                forecast_step_metrics.append({\n",
        "                    'step': step + 1,\n",
        "                    'rmse': step_rmse,\n",
        "                    'mae': step_mae\n",
        "                })\n",
        "\n",
        "        print(\"\\n=== Overall Metrics ===\")\n",
        "        print(f\"RMSE: {overall_rmse:.4f}\")\n",
        "        print(f\"MAE : {overall_mae:.4f}\")\n",
        "\n",
        "        self.results['lstm'] = {\n",
        "            'overall_rmse': overall_rmse,\n",
        "            'overall_mae': overall_mae,\n",
        "            'predictions': predictions.tolist(),\n",
        "            'targets': targets.tolist(),\n",
        "            'num_samples': len(predictions),\n",
        "            'step_metrics': forecast_step_metrics # Add step metrics\n",
        "        }\n",
        "\n",
        "        return overall_rmse, overall_mae, predictions, targets\n",
        "\n",
        "    def evaluate_hybrid(self, model_path, test_dataset):\n",
        "        print(\"\\n=== Evaluating Hybrid CNN-LSTM Model ===\")\n",
        "        checkpoint = torch.load(model_path, map_location=self.device, weights_only=False)\n",
        "        config = checkpoint.get('config', {})\n",
        "        model, _ = self.load_model(\n",
        "            HybridCNNLSTM,\n",
        "            model_path,\n",
        "            sequence_length=config.get('sequence_length', 20),\n",
        "            lstm_hidden_size=config.get('lstm_hidden_size', 128),\n",
        "            forecast_horizon=config.get('forecast_horizon', 4)\n",
        "        )\n",
        "\n",
        "        test_loader = DataLoader(test_dataset, batch_size=8, shuffle=False, num_workers=2)\n",
        "        all_nowcast_pred, all_nowcast_target, all_forecast_pred, all_forecast_target = [], [], [], []\n",
        "        with torch.no_grad():\n",
        "            for image_sequences, historical_irradiance, future_irradiance in test_loader:\n",
        "                image_sequences = image_sequences.to(self.device)\n",
        "                historical_irradiance = historical_irradiance.to(self.device)\n",
        "                future_irradiance = future_irradiance.to(self.device)\n",
        "                nowcasts, forecasts = model(image_sequences)\n",
        "                all_nowcast_pred.append(nowcasts.squeeze(-1).cpu().numpy())\n",
        "                all_nowcast_target.append(historical_irradiance.squeeze(-1).cpu().numpy())\n",
        "                all_forecast_pred.append(forecasts.cpu().numpy())\n",
        "                all_forecast_target.append(future_irradiance.cpu().numpy())\n",
        "\n",
        "        nowcast_pred = np.concatenate(all_nowcast_pred, axis=0)\n",
        "        nowcast_target = np.concatenate(all_nowcast_target, axis=0)\n",
        "        forecast_pred = np.concatenate(all_forecast_pred, axis=0)\n",
        "        forecast_target = np.concatenate(all_forecast_target, axis=0)\n",
        "\n",
        "        nowcast_rmse = np.sqrt(mean_squared_error(nowcast_target.flatten(), nowcast_pred.flatten()))\n",
        "        nowcast_mae = mean_absolute_error(nowcast_target.flatten(), nowcast_pred.flatten())\n",
        "        forecast_rmse = np.sqrt(mean_squared_error(forecast_target.flatten(), forecast_pred.flatten()))\n",
        "        forecast_mae = mean_absolute_error(forecast_target.flatten(), forecast_pred.flatten())\n",
        "\n",
        "        forecast_step_metrics = []\n",
        "        forecast_horizon = forecast_pred.shape[1]\n",
        "        for step in range(forecast_horizon):\n",
        "            step_rmse = np.sqrt(mean_squared_error(forecast_target[:, step], forecast_pred[:, step]))\n",
        "            step_mae = mean_absolute_error(forecast_target[:, step], forecast_pred[:, step])\n",
        "            forecast_step_metrics.append({\n",
        "                'step': step + 1,\n",
        "                'rmse': step_rmse,\n",
        "                'mae': step_mae\n",
        "            })\n",
        "\n",
        "        self.results['hybrid'] = {\n",
        "            'nowcast_rmse': nowcast_rmse,\n",
        "            'nowcast_mae': nowcast_mae,\n",
        "            'forecast_rmse': forecast_rmse,\n",
        "            'forecast_mae': forecast_mae,\n",
        "            'forecast_step_metrics': forecast_step_metrics,\n",
        "            'num_samples': len(forecast_pred)\n",
        "        }\n",
        "\n",
        "        print(f\"Hybrid Results:\")\n",
        "        print(f\"  Nowcast RMSE: {nowcast_rmse:.2f} W/m²\")\n",
        "        print(f\"  Nowcast MAE: {nowcast_mae:.2f} W/m²\")\n",
        "        print(f\"  Forecast RMSE: {forecast_rmse:.2f} W/m²\")\n",
        "        print(f\"  Forecast MAE: {forecast_mae:.2f} W/m²\")\n",
        "        print(f\"  Samples: {len(forecast_pred)}\")\n",
        "\n",
        "        return (nowcast_rmse, nowcast_mae, forecast_rmse, forecast_mae,\n",
        "                forecast_step_metrics, nowcast_pred, forecast_pred)\n",
        "\n",
        "\n",
        "    def plot_results(self, save_dir='evaluation_plots'):\n",
        "        \"\"\"Create visualization plots\"\"\"\n",
        "        os.makedirs(save_dir, exist_ok=True)\n",
        "\n",
        "        # CNN scatter plot\n",
        "        if 'cnn' in self.results:\n",
        "            plt.figure(figsize=(10, 8))\n",
        "\n",
        "            targets = np.array(self.results['cnn']['targets'])\n",
        "            predictions = np.array(self.results['cnn']['predictions'])\n",
        "\n",
        "            plt.subplot(2, 2, 1)\n",
        "            plt.scatter(targets, predictions, alpha=0.6, s=20)\n",
        "            plt.plot([targets.min(), targets.max()], [targets.min(), targets.max()], 'r--', lw=2)\n",
        "            plt.xlabel('Actual Irradiance (W/m²)')\n",
        "            plt.ylabel('Predicted Irradiance (W/m²)')\n",
        "            plt.title(f'CNN Nowcasting (RMSE: {self.results[\"cnn\"][\"rmse\"]:.2f} W/m²)')\n",
        "            plt.grid(True, alpha=0.3)\n",
        "\n",
        "            # Residuals plot\n",
        "            plt.subplot(2, 2, 2)\n",
        "            residuals = predictions - targets\n",
        "            plt.scatter(targets, residuals, alpha=0.6, s=20)\n",
        "            plt.axhline(y=0, color='r', linestyle='--')\n",
        "            plt.xlabel('Actual Irradiance (W/m²)')\n",
        "            plt.ylabel('Residuals (W/m²)')\n",
        "            plt.title('CNN Residuals')\n",
        "            plt.grid(True, alpha=0.3)\n",
        "\n",
        "            plt.tight_layout()\n",
        "            plt.savefig(f'{save_dir}/cnn_evaluation.png', dpi=300, bbox_inches='tight')\n",
        "            plt.show()\n",
        "            plt.close()\n",
        "\n",
        "        # LSTM overall performance\n",
        "        if 'lstm' in self.results:\n",
        "            overall_rmse = self.results['lstm']['overall_rmse']\n",
        "            overall_mae = self.results['lstm']['overall_mae']\n",
        "\n",
        "            plt.figure(figsize=(8, 6))\n",
        "            bar_labels = ['RMSE', 'MAE']\n",
        "            error_values = [overall_rmse, overall_mae]\n",
        "\n",
        "            plt.bar(bar_labels, error_values, color=['skyblue', 'lightcoral'], alpha=0.7)\n",
        "            plt.ylabel('Error (W/m²)')\n",
        "            plt.title('LSTM Overall Performance')\n",
        "            plt.grid(True, alpha=0.3, axis='y')\n",
        "\n",
        "            # Add value labels on bars\n",
        "            for i, val in enumerate(error_values):\n",
        "                plt.text(i, val + 1, f'{val:.2f}', ha='center', va='bottom')\n",
        "\n",
        "            plt.tight_layout()\n",
        "            plt.savefig(f'{save_dir}/lstm_overall_evaluation.png', dpi=300, bbox_inches='tight')\n",
        "            plt.show()\n",
        "            plt.close()\n",
        "\n",
        "\n",
        "        # Model comparison\n",
        "        if len(self.results) > 1:\n",
        "            plt.figure(figsize=(12, 8))\n",
        "\n",
        "            models = []\n",
        "            rmse_values = []\n",
        "            mae_values = []\n",
        "\n",
        "            if 'cnn' in self.results:\n",
        "                models.append('CNN\\nNowcasting')\n",
        "                rmse_values.append(self.results['cnn']['rmse'])\n",
        "                mae_values.append(self.results['cnn']['mae'])\n",
        "\n",
        "            if 'lstm' in self.results:\n",
        "                models.append('LSTM\\nForecasting')\n",
        "                rmse_values.append(self.results['lstm']['overall_rmse'])\n",
        "                mae_values.append(self.results['lstm']['overall_mae'])\n",
        "\n",
        "            if 'hybrid' in self.results:\n",
        "                models.append('Hybrid\\nNowcast')\n",
        "                rmse_values.append(self.results['hybrid']['nowcast_rmse'])\n",
        "                mae_values.append(self.results['hybrid']['nowcast_mae'])\n",
        "\n",
        "                models.append('Hybrid\\nForecast')\n",
        "                rmse_values.append(self.results['hybrid']['forecast_rmse'])\n",
        "                mae_values.append(self.results['hybrid']['forecast_mae'])\n",
        "\n",
        "            x = np.arange(len(models))\n",
        "            width = 0.35\n",
        "\n",
        "            plt.subplot(1, 1, 1)\n",
        "            plt.bar(x - width/2, rmse_values, width, label='RMSE', color='skyblue', alpha=0.8)\n",
        "            plt.bar(x + width/2, mae_values, width, label='MAE', color='lightcoral', alpha=0.8)\n",
        "\n",
        "            plt.xlabel('Models')\n",
        "            plt.ylabel('Error (W/m²)')\n",
        "            plt.title('Model Performance Comparison')\n",
        "            plt.xticks(x, models)\n",
        "            plt.legend()\n",
        "            plt.grid(True, alpha=0.3)\n",
        "\n",
        "            # Add value labels on bars\n",
        "            for i, (rmse, mae) in enumerate(zip(rmse_values, mae_values)):\n",
        "                plt.text(i - width/2, rmse + 1, f'{rmse:.1f}', ha='center', va='bottom')\n",
        "                plt.text(i + width/2, mae + 1, f'{mae:.1f}', ha='center', va='bottom')\n",
        "\n",
        "            plt.tight_layout()\n",
        "            plt.savefig(f'{save_dir}/model_comparison.png', dpi=300, bbox_inches='tight')\n",
        "            plt.show()\n",
        "            plt.close()\n",
        "\n",
        "        print(f\"\\nPlots saved to {save_dir}/\")\n",
        "\n",
        "    def save_results(self, filename='evaluation_results.json'):\n",
        "        results_with_metadata = {\n",
        "            'evaluation_timestamp': datetime.now().isoformat(),\n",
        "            'device': str(self.device),\n",
        "            'results': self.results\n",
        "        }\n",
        "        with open(filename, 'w') as f:\n",
        "            json.dump(results_with_metadata, f, indent=2)\n",
        "        print(f\"\\nResults saved to {filename}\")\n",
        "\n",
        "    def generate_report(self, filename='evaluation_report.txt'):\n",
        "        with open(filename, 'w') as f:\n",
        "            f.write(\"=\"*80 + \"\\n\")\n",
        "            f.write(\"SOLAR IRRADIANCE FORECASTING - MODEL EVALUATION REPORT\\n\")\n",
        "            f.write(\"=\"*80 + \"\\n\")\n",
        "            f.write(f\"Generated: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\\n\")\n",
        "            f.write(f\"Device: {self.device}\\n\\n\")\n",
        "            if 'cnn' in self.results:\n",
        "                r = self.results['cnn']\n",
        "                f.write(\"CNN NOWCASTING MODEL\\n\")\n",
        "                f.write(\"-\"*30 + \"\\n\")\n",
        "                f.write(f\"RMSE: {r['rmse']:.2f} W/m²\\n\")\n",
        "                f.write(f\"MAE: {r['mae']:.2f} W/m²\\n\\n\")\n",
        "            if 'lstm' in self.results:\n",
        "                r = self.results['lstm']\n",
        "                f.write(\"LSTM FORECASTING MODEL\\n\")\n",
        "                f.write(\"-\"*30 + \"\\n\")\n",
        "                f.write(f\"RMSE: {r['overall_rmse']:.2f} W/m²\\n\")\n",
        "                f.write(f\"MAE: {r['overall_mae']:.2f} W/m²\\n\\n\")\n",
        "            if 'hybrid' in self.results:\n",
        "                r = self.results['hybrid']\n",
        "                f.write(\"HYBRID CNN-LSTM MODEL\\n\")\n",
        "                f.write(\"-\"*30 + \"\\n\")\n",
        "                f.write(f\"Nowcast RMSE: {r['nowcast_rmse']:.2f} W/m²\\n\")\n",
        "                f.write(f\"Nowcast MAE: {r['nowcast_mae']:.2f} W/m²\\n\")\n",
        "                f.write(f\"Forecast RMSE: {r['forecast_rmse']:.2f} W/m²\\n\")\n",
        "                f.write(f\"Forecast MAE: {r['forecast_mae']:.2f} W/m²\\n\\n\")\n",
        "        print(f\"Report saved to {filename}\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "4M0T_Uf2y3PX"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3b7982a8",
        "outputId": "f0a5b8a7-a03c-4ce6-8a9b-fecfcd52e11b"
      },
      "source": [
        "evaluator = ModelEvaluator()\n",
        "model_paths = {\n",
        "    'cnn': r'/content/drive/MyDrive/models/best_cnn_model.pth',\n",
        "    'lstm': r'/content/drive/MyDrive/models(LSTM)/best_lstm_model.pth',\n",
        "    'hybrid': r'/content/best_hybrid_model.pth'\n",
        "}\n",
        "test_config = {\n",
        "    'image_dir': r'/content/drive/MyDrive/GIRASOL_DATASET/2019_01_20/infrared',\n",
        "    'irradiance_file': r'/content/drive/MyDrive/GIRASOL_DATASET/2019_01_20/pyranometer/2019_01_20.csv',\n",
        "    'sequence_length': 20,\n",
        "    'forecast_horizon': 4\n",
        "}"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if os.path.exists(model_paths['cnn']):\n",
        "  baseline_model, _ = evaluator.load_model(EfficientNetRegression, model_paths['cnn'])\n",
        "  test_dataset = MultiDayDataset(\n",
        "        image_paths=[os.path.join(test_config['image_dir'], f) for f in sorted(os.listdir(test_config['image_dir'])) if f.endswith(('.png', '.jpg', '.jpeg'))],\n",
        "        irradiance_values=pd.read_csv(test_config['irradiance_file']).iloc[:, 1].values.astype(np.float32)\n",
        "    )\n",
        "  preds, targets = evaluator.evaluate_model(baseline_model, \"Baseline CNN\", test_dataset)\n",
        "  evaluator.plot_results() # Re-adding the plotting call"
      ],
      "metadata": {
        "id": "r1rzEXI8g0ng"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "81ba418d",
        "outputId": "42992cdb-db75-4c0f-ad01-9b3f9d9458fc"
      },
      "source": [
        "if os.path.exists(model_paths['cnn']):\n",
        "    print(\"Preparing CNN test dataset...\")\n",
        "    cnn_test_dataset = MultiDayDataset(\n",
        "        image_paths=[os.path.join(test_config['image_dir'], f) for f in sorted(os.listdir(test_config['image_dir'])) if f.endswith(('.png', '.jpg', '.jpeg'))],\n",
        "        irradiance_values=pd.read_csv(test_config['irradiance_file']).iloc[:, 1].values.astype(np.float32)\n",
        "    )\n",
        "    evaluator.evaluate_cnn(model_paths['cnn'], cnn_test_dataset)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Preparing CNN test dataset...\n",
            "\n",
            "=== Evaluating CNN Nowcasting Model ===\n",
            "CNN Results:\n",
            "  RMSE: 44.83 W/m²\n",
            "  MAE: 35.90 W/m²\n",
            "  Samples: 1712\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "98f7acf3",
        "outputId": "712d4edb-98ab-4807-ab2d-82340fd83e26"
      },
      "source": [
        "if os.path.exists(model_paths['lstm']):\n",
        "    print(\"Preparing LSTM test dataset...\")\n",
        "    lstm_test_dataset = MultiDayTimeSeriesDataset(\n",
        "        irradiance_file=test_config['irradiance_file'],\n",
        "        sequence_length=test_config['sequence_length'],\n",
        "        forecast_horizon=test_config['forecast_horizon']\n",
        "    )\n",
        "    evaluator.evaluate_lstm(model_paths['lstm'], lstm_test_dataset)"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Preparing LSTM test dataset...\n",
            "\n",
            "=== Evaluating LSTM Forecasting Model ===\n",
            "\n",
            "=== Overall Metrics ===\n",
            "RMSE: 27.3672\n",
            "MAE : 16.3862\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "48f7d301"
      },
      "source": [
        "if os.path.exists(model_paths['hybrid']):\n",
        "    print(\"Preparing Hybrid test dataset...\")\n",
        "    hybrid_test_dataset = SolarSequenceDataset(\n",
        "        image_dir=test_config['image_dir'],\n",
        "        irradiance_file=test_config['irradiance_file'],\n",
        "        sequence_length=test_config['sequence_length'],\n",
        "        forecast_horizon=test_config['forecast_horizon']\n",
        "    )\n",
        "    evaluator.evaluate_hybrid(model_paths['hybrid'], hybrid_test_dataset)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d594ed1d",
        "outputId": "53494745-df6f-49b0-fc1f-c2b958e819b4"
      },
      "source": [
        "evaluator.plot_results()\n",
        "evaluator.save_results()\n",
        "evaluator.generate_report()\n",
        "\n",
        "print(\"\\n=== Evaluation Complete ===\")\n",
        "print(\"Check:\")\n",
        "print(\"- evaluation_results.json\")\n",
        "print(\"- evaluation_report.txt\")\n",
        "print(\"- evaluation_plots/\")"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Plots saved to evaluation_plots/\n",
            "\n",
            "Results saved to evaluation_results.json\n",
            "Report saved to evaluation_report.txt\n",
            "\n",
            "=== Evaluation Complete ===\n",
            "Check:\n",
            "- evaluation_results.json\n",
            "- evaluation_report.txt\n",
            "- evaluation_plots/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "print(torch.__version__)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ey6Mo2liSE5Y",
        "outputId": "84a7d7e3-f9f4-49ce-9c3b-21c3fea5bc30"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.8.0+cu126\n"
          ]
        }
      ]
    }
  ]
}