{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V5E1"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class SolarCNNRegression(nn.Module):\n",
        "\n",
        "\n",
        "    def __init__(self, input_channels=3, num_classes=1):\n",
        "        super(SolarCNNRegression, self).__init__()\n",
        "\n",
        "\n",
        "        self.features = nn.Sequential(\n",
        "\n",
        "            nn.Conv2d(input_channels, 32, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(2, 2),\n",
        "\n",
        "            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(2, 2),\n",
        "\n",
        "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(2, 2),\n",
        "\n",
        "            nn.Conv2d(128, 256, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(2, 2),\n",
        "\n",
        "            nn.Conv2d(256, 512, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(512),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.AdaptiveAvgPool2d((1, 1))\n",
        "        )\n",
        "\n",
        "\n",
        "        self.regressor = nn.Sequential(\n",
        "            nn.Flatten(),\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(512, 256),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(0.3),\n",
        "            nn.Linear(256, 128),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Linear(128, num_classes)\n",
        "        )\n",
        "\n",
        "\n",
        "        self._initialize_weights()\n",
        "\n",
        "    def _initialize_weights(self):\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
        "                if m.bias is not None:\n",
        "                    nn.init.constant_(m.bias, 0)\n",
        "            elif isinstance(m, nn.BatchNorm2d):\n",
        "                nn.init.constant_(m.weight, 1)\n",
        "                nn.init.constant_(m.bias, 0)\n",
        "            elif isinstance(m, nn.Linear):\n",
        "                nn.init.normal_(m.weight, 0, 0.01)\n",
        "                nn.init.constant_(m.bias, 0)\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        features = self.features(x)\n",
        "\n",
        "\n",
        "        irradiance = self.regressor(features)\n",
        "\n",
        "        return irradiance\n",
        "\n",
        "\n",
        "    def get_features(self, x):\n",
        "\n",
        "        with torch.no_grad():\n",
        "            features = self.features(x)\n",
        "            return features.flatten(1)\n",
        "\n",
        "\n",
        "class SolarCNNWithFeatureExtraction(SolarCNNRegression):\n",
        "\n",
        "\n",
        "    def __init__(self, input_channels=3, feature_dim=512):\n",
        "        super().__init__(input_channels, 1)\n",
        "        self.feature_dim = feature_dim\n",
        "\n",
        "\n",
        "        self.feature_projector = nn.Sequential(\n",
        "            nn.Linear(512, feature_dim),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(0.2)\n",
        "        )\n",
        "\n",
        "    def forward(self, x, return_features=False):\n",
        "\n",
        "        conv_features = self.features(x)\n",
        "        flattened_features = conv_features.flatten(1)\n",
        "\n",
        "\n",
        "        irradiance = self.regressor[-3:](self.regressor[:-3](flattened_features))\n",
        "\n",
        "        if return_features:\n",
        "\n",
        "            projected_features = self.feature_projector(flattened_features)\n",
        "            return irradiance, projected_features\n",
        "\n",
        "        return irradiance\n",
        "\n",
        "\n",
        "class SolarCNN(SolarCNNRegression):\n",
        "\n",
        "    pass"
      ],
      "metadata": {
        "id": "2x6yHW8yh_7h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hNU19BhGiEmQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import cv2\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "class SolarIrradianceDataset(Dataset):\n",
        "\n",
        "\n",
        "    def __init__(self, image_dir, irradiance_file, transform=None, target_size=(240, 320)):\n",
        "        self.image_dir = image_dir\n",
        "        self.transform = transform\n",
        "        self.target_size = target_size\n",
        "\n",
        "\n",
        "        if irradiance_file.endswith('.csv'):\n",
        "            df = pd.read_csv(irradiance_file)\n",
        "\n",
        "            self.irradiance_values = df.iloc[:, 1].values.astype(np.float32)\n",
        "        else:\n",
        "            self.irradiance_values = np.loadtxt(irradiance_file, delimiter=',')[:, 1].astype(np.float32)\n",
        "\n",
        "\n",
        "        self.image_files = sorted([f for f in os.listdir(image_dir) if f.endswith(('.png', '.jpg', '.jpeg'))])\n",
        "\n",
        "\n",
        "        min_length = min(len(self.image_files), len(self.irradiance_values))\n",
        "        self.image_files = self.image_files[:min_length]\n",
        "        self.irradiance_values = self.irradiance_values[:min_length]\n",
        "\n",
        "\n",
        "        self.image_processor = IRImageProcessor(target_size=target_size)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_files)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "\n",
        "        img_path = os.path.join(self.image_dir, self.image_files[idx])\n",
        "\n",
        "\n",
        "        img = cv2.imread(img_path)\n",
        "        if img is None:\n",
        "\n",
        "            img = cv2.imread(img_path, cv2.IMREAD_ANYDEPTH)\n",
        "            if img is not None:\n",
        "\n",
        "                img = self.image_processor.process_single_image(img_path)\n",
        "            else:\n",
        "                raise ValueError(f\"Could not load image: {img_path}\")\n",
        "        else:\n",
        "\n",
        "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "\n",
        "        img_tensor = torch.tensor(img).permute(2, 0, 1).float() / 255.0\n",
        "\n",
        "\n",
        "        if self.transform:\n",
        "            img_tensor = self.transform(img_tensor)\n",
        "\n",
        "\n",
        "        irradiance = torch.tensor(self.irradiance_values[idx], dtype=torch.float32)\n",
        "\n",
        "        return img_tensor, irradiance\n",
        "\n",
        "\n",
        "class SolarSequenceDataset(Dataset):\n",
        "\n",
        "\n",
        "    def __init__(self, image_dir, irradiance_file, sequence_length=20, forecast_horizon=4, transform=None, target_size=(240, 320)):\n",
        "        self.image_dir = image_dir\n",
        "        self.sequence_length = sequence_length\n",
        "        self.forecast_horizon = forecast_horizon\n",
        "        self.transform = transform\n",
        "        self.target_size = target_size\n",
        "\n",
        "\n",
        "        if irradiance_file.endswith('.csv'):\n",
        "            df = pd.read_csv(irradiance_file)\n",
        "            self.irradiance_values = df.iloc[:, 1].values.astype(np.float32)\n",
        "        else:\n",
        "            self.irradiance_values = np.loadtxt(irradiance_file, delimiter=',')[:, 1].astype(np.float32)\n",
        "\n",
        "\n",
        "        self.image_files = sorted([f for f in os.listdir(image_dir) if f.endswith(('.png', '.jpg', '.jpeg'))])\n",
        "\n",
        "\n",
        "        min_length = min(len(self.image_files), len(self.irradiance_values))\n",
        "        self.image_files = self.image_files[:min_length]\n",
        "        self.irradiance_values = self.irradiance_values[:min_length]\n",
        "\n",
        "\n",
        "        self.valid_indices = list(range(len(self.image_files) - sequence_length - forecast_horizon + 1))\n",
        "\n",
        "\n",
        "        self.image_processor = IRImageProcessor(target_size=target_size)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.valid_indices)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        start_idx = self.valid_indices[idx]\n",
        "\n",
        "\n",
        "        image_sequence = []\n",
        "        for i in range(start_idx, start_idx + self.sequence_length):\n",
        "            img_path = os.path.join(self.image_dir, self.image_files[i])\n",
        "\n",
        "\n",
        "            img = cv2.imread(img_path)\n",
        "            if img is None:\n",
        "                img = cv2.imread(img_path, cv2.IMREAD_ANYDEPTH)\n",
        "                if img is not None:\n",
        "                    img = self.image_processor.process_single_image(img_path)\n",
        "                else:\n",
        "                    raise ValueError(f\"Could not load image: {img_path}\")\n",
        "            else:\n",
        "                img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "\n",
        "            img_tensor = torch.tensor(img).permute(2, 0, 1).float() / 255.0\n",
        "\n",
        "\n",
        "            if self.transform:\n",
        "                img_tensor = self.transform(img_tensor)\n",
        "\n",
        "            image_sequence.append(img_tensor)\n",
        "\n",
        "\n",
        "        image_sequence = torch.stack(image_sequence)\n",
        "\n",
        "\n",
        "        historical_irradiance = torch.tensor(\n",
        "            self.irradiance_values[start_idx:start_idx + self.sequence_length],\n",
        "            dtype=torch.float32\n",
        "        ).unsqueeze(-1)\n",
        "\n",
        "\n",
        "        future_irradiance = torch.tensor(\n",
        "            self.irradiance_values[start_idx + self.sequence_length: start_idx + self.sequence_length + self.forecast_horizon],\n",
        "            dtype=torch.float32\n",
        "        )\n",
        "\n",
        "        return image_sequence, historical_irradiance, future_irradiance\n",
        "\n",
        "\n",
        "class SolarTimeSeriesDataset(Dataset):\n",
        "\n",
        "\n",
        "    def __init__(self, irradiance_file, sequence_length=20, forecast_horizon=4):\n",
        "        self.sequence_length = sequence_length\n",
        "        self.forecast_horizon = forecast_horizon\n",
        "\n",
        "\n",
        "        if irradiance_file.endswith('.csv'):\n",
        "            df = pd.read_csv(irradiance_file)\n",
        "            self.data = df.iloc[:, 1].values.astype(np.float32)\n",
        "        else:\n",
        "            self.data = np.loadtxt(irradiance_file, delimiter=',')[:, 1].astype(np.float32)\n",
        "\n",
        "\n",
        "        self.valid_indices = list(range(len(self.data) - sequence_length - forecast_horizon + 1))\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.valid_indices)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        start_idx = self.valid_indices[idx]\n",
        "\n",
        "\n",
        "        x = torch.tensor(\n",
        "            self.data[start_idx:start_idx + self.sequence_length],\n",
        "            dtype=torch.float32\n",
        "        ).unsqueeze(-1)\n",
        "\n",
        "\n",
        "        y = torch.tensor(\n",
        "            self.data[start_idx + self.sequence_length: start_idx + self.sequence_length + self.forecast_horizon],\n",
        "            dtype=torch.float32\n",
        "        )\n",
        "\n",
        "        return x, y\n",
        "\n",
        "\n",
        "class GSIDataset(SolarIrradianceDataset):\n",
        "\n",
        "\n",
        "    def __init__(self, image_dir, gsi_file):\n",
        "        super().__init__(image_dir, gsi_file)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_tensor, irradiance = super().__getitem__(idx)\n",
        "        return img_tensor, irradiance\n",
        "\n",
        "\n",
        "class GSITimeSeriesDataset(SolarTimeSeriesDataset):\n",
        "\n",
        "\n",
        "    def __init__(self, gsi_values, sequence_length=10):\n",
        "        self.sequence_length = sequence_length\n",
        "        self.data = gsi_values.astype(np.float32)\n",
        "        self.valid_indices = list(range(len(self.data) - sequence_length))\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        start_idx = self.valid_indices[idx]\n",
        "        x = torch.tensor(\n",
        "            self.data[start_idx:start_idx + self.sequence_length],\n",
        "            dtype=torch.float32\n",
        "        ).unsqueeze(-1)\n",
        "        y = torch.tensor(self.data[start_idx + self.sequence_length], dtype=torch.float32)\n",
        "        return x, y"
      ],
      "metadata": {
        "id": "3DmP6s5CgIZ1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class SolarLSTMForecasting(nn.Module):\n",
        "\n",
        "\n",
        "    def __init__(self, input_size=1, hidden_size=128, num_layers=2, output_size=4, dropout=0.2):\n",
        "        super(SolarLSTMForecasting, self).__init__()\n",
        "\n",
        "        self.input_size = input_size\n",
        "        self.hidden_size = hidden_size\n",
        "        self.num_layers = num_layers\n",
        "        self.output_size = output_size\n",
        "\n",
        "\n",
        "        self.lstm = nn.LSTM(\n",
        "            input_size=input_size,\n",
        "            hidden_size=hidden_size,\n",
        "            num_layers=num_layers,\n",
        "            bidirectional=True,\n",
        "            batch_first=True,\n",
        "            dropout=dropout if num_layers > 1 else 0\n",
        "        )\n",
        "\n",
        "\n",
        "        lstm_output_size = hidden_size * 2\n",
        "\n",
        "        self.fc_layers = nn.Sequential(\n",
        "            nn.Linear(lstm_output_size, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(dropout),\n",
        "\n",
        "            nn.Linear(128, 64),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(dropout),\n",
        "\n",
        "            nn.Linear(64, output_size)\n",
        "        )\n",
        "\n",
        "        self._initialize_weights()\n",
        "\n",
        "    def _initialize_weights(self):\n",
        "        for name, param in self.lstm.named_parameters():\n",
        "            if 'weight_ih' in name:\n",
        "                nn.init.xavier_uniform_(param.data)\n",
        "            elif 'weight_hh' in name:\n",
        "                nn.init.orthogonal_(param.data)\n",
        "            elif 'bias' in name:\n",
        "                param.data.fill_(0)\n",
        "\n",
        "\n",
        "                n = param.size(0)\n",
        "                start, end = n // 4, n // 2\n",
        "                param.data[start:end].fill_(1.)\n",
        "\n",
        "        for m in self.fc_layers:\n",
        "            if isinstance(m, nn.Linear):\n",
        "                nn.init.xavier_uniform_(m.weight)\n",
        "                nn.init.constant_(m.bias, 0)\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "\n",
        "        lstm_out, (hidden, cell) = self.lstm(x)\n",
        "\n",
        "\n",
        "        last_output = lstm_out[:, -1, :]\n",
        "\n",
        "\n",
        "        forecast = self.fc_layers(last_output)\n",
        "\n",
        "        return forecast\n",
        "\n",
        "\n",
        "class HybridCNNLSTM(nn.Module):\n",
        "\n",
        "\n",
        "    def __init__(self, cnn_model=None, feature_dim=512, sequence_length=20, lstm_hidden_size=128, forecast_horizon=4):\n",
        "        super(HybridCNNLSTM, self).__init__()\n",
        "\n",
        "        self.sequence_length = sequence_length\n",
        "        self.forecast_horizon = forecast_horizon\n",
        "\n",
        "\n",
        "        if cnn_model is None:\n",
        "\n",
        "            from __main__ import SolarCNNWithFeatureExtraction\n",
        "            self.cnn = SolarCNNWithFeatureExtraction(feature_dim=feature_dim)\n",
        "        else:\n",
        "            self.cnn = cnn_model\n",
        "\n",
        "\n",
        "        self.lstm = SolarLSTMForecasting(\n",
        "            input_size=1,\n",
        "            hidden_size=lstm_hidden_size,\n",
        "            output_size=forecast_horizon\n",
        "        )\n",
        "\n",
        "\n",
        "        self.freeze_cnn = False\n",
        "\n",
        "    def set_cnn_trainable(self, trainable=True):\n",
        "\n",
        "        for param in self.cnn.parameters():\n",
        "            param.requires_grad = trainable\n",
        "        self.freeze_cnn = not trainable\n",
        "\n",
        "    def forward(self, image_sequence):\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        batch_size, seq_len, channels, height, width = image_sequence.shape\n",
        "\n",
        "\n",
        "        images_flat = image_sequence.view(-1, channels, height, width)\n",
        "\n",
        "\n",
        "        nowcasts = self.cnn(images_flat)\n",
        "        nowcasts = nowcasts.view(batch_size, seq_len, 1)\n",
        "\n",
        "\n",
        "        forecasts = self.lstm(nowcasts)\n",
        "\n",
        "        return nowcasts, forecasts\n",
        "\n",
        "    def predict_from_sequence(self, image_sequence):\n",
        "\n",
        "        self.eval()\n",
        "        with torch.no_grad():\n",
        "            nowcasts, forecasts = self.forward(image_sequence)\n",
        "        return nowcasts, forecasts\n",
        "\n",
        "\n",
        "class SolarLSTM(nn.Module):\n",
        "\n",
        "\n",
        "    def __init__(self, input_size=1, hidden_size=128, output_size=1):\n",
        "        super(SolarLSTM, self).__init__()\n",
        "        self.lstm = nn.LSTM(input_size, hidden_size, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        lstm_out, _ = self.lstm(x)\n",
        "        output = self.fc(lstm_out[:, -1, :])\n",
        "        return output"
      ],
      "metadata": {
        "id": "K5FOR1iagO1n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
        "import json\n",
        "import cv2\n",
        "import pandas as pd\n",
        "from preprocess import IRImageProcessor\n",
        "\n",
        "class SolarIrradianceDataset(Dataset):\n",
        "\n",
        "\n",
        "    def __init__(self, image_dir, irradiance_file, transform=None, target_size=(240, 320)):\n",
        "        self.image_dir = image_dir\n",
        "        self.transform = transform\n",
        "        self.target_size = target_size\n",
        "\n",
        "\n",
        "        if irradiance_file.endswith('.csv'):\n",
        "            df = pd.read_csv(irradiance_file)\n",
        "\n",
        "            self.irradiance_values = df.iloc[:, 1].values.astype(np.float32)\n",
        "        else:\n",
        "            self.irradiance_values = np.loadtxt(irradiance_file, delimiter=',')[:, 1].astype(np.float32)\n",
        "\n",
        "\n",
        "        self.image_files = sorted([f for f in os.listdir(image_dir) if f.endswith(('.png', '.jpg', '.jpeg'))])\n",
        "\n",
        "\n",
        "        min_length = min(len(self.image_files), len(self.irradiance_values))\n",
        "        self.image_files = self.image_files[:min_length]\n",
        "        self.irradiance_values = self.irradiance_values[:min_length]\n",
        "\n",
        "\n",
        "        self.image_processor = IRImageProcessor(target_size=target_size)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_files)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "\n",
        "        img_path = os.path.join(self.image_dir, self.image_files[idx])\n",
        "\n",
        "\n",
        "        img = cv2.imread(img_path)\n",
        "        if img is None:\n",
        "\n",
        "            img = cv2.imread(img_path, cv2.IMREAD_ANYDEPTH)\n",
        "            if img is not None:\n",
        "\n",
        "                img = self.image_processor.process_single_image(img_path)\n",
        "            else:\n",
        "                raise ValueError(f\"Could not load image: {img_path}\")\n",
        "        else:\n",
        "\n",
        "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "\n",
        "        img_tensor = torch.tensor(img).permute(2, 0, 1).float() / 255.0\n",
        "\n",
        "\n",
        "        if self.transform:\n",
        "            img_tensor = self.transform(img_tensor)\n",
        "\n",
        "\n",
        "        irradiance = torch.tensor(self.irradiance_values[idx], dtype=torch.float32)\n",
        "\n",
        "        return img_tensor, irradiance\n",
        "\n",
        "\n",
        "class SolarSequenceDataset(Dataset):\n",
        "\n",
        "\n",
        "    def __init__(self, image_paths, irradiance_values, sequence_length=20, forecast_horizon=4, transform=None, target_size=(240, 320)):\n",
        "        self.image_paths = image_paths\n",
        "        self.irradiance_values = irradiance_values\n",
        "        self.sequence_length = sequence_length\n",
        "        self.forecast_horizon = forecast_horizon\n",
        "        self.transform = transform\n",
        "        self.target_size = target_size\n",
        "\n",
        "\n",
        "        self.valid_indices = list(range(len(self.image_paths) - sequence_length - forecast_horizon + 1))\n",
        "\n",
        "\n",
        "        self.image_processor = IRImageProcessor(target_size=target_size)\n",
        "\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.valid_indices)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        start_idx = self.valid_indices[idx]\n",
        "\n",
        "\n",
        "        image_sequence = []\n",
        "        for i in range(start_idx, start_idx + self.sequence_length):\n",
        "            img_path = self.image_paths[i]\n",
        "\n",
        "\n",
        "            img = cv2.imread(img_path)\n",
        "            if img is None:\n",
        "                img = cv2.imread(img_path, cv2.IMREAD_ANYDEPTH)\n",
        "                if img is not None:\n",
        "                    img = self.image_processor.process_single_image(img_path)\n",
        "                else:\n",
        "                    raise ValueError(f\"Could not load image: {img_path}\")\n",
        "            else:\n",
        "                img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "\n",
        "            img_tensor = torch.tensor(img).permute(2, 0, 1).float() / 255.0\n",
        "\n",
        "\n",
        "            if self.transform:\n",
        "                img_tensor = self.transform(img_tensor)\n",
        "\n",
        "            image_sequence.append(img_tensor)\n",
        "\n",
        "\n",
        "        image_sequence = torch.stack(image_sequence)\n",
        "\n",
        "\n",
        "        historical_irradiance = torch.tensor(\n",
        "            self.irradiance_values[start_idx:start_idx + self.sequence_length],\n",
        "            dtype=torch.float32\n",
        "        ).unsqueeze(-1)\n",
        "\n",
        "\n",
        "        future_irradiance = torch.tensor(\n",
        "            self.irradiance_values[start_idx + self.sequence_length: start_idx + self.sequence_length + self.forecast_horizon],\n",
        "            dtype=torch.float32\n",
        "        )\n",
        "\n",
        "        return image_sequence, historical_irradiance, future_irradiance\n",
        "\n",
        "\n",
        "class SolarTimeSeriesDataset(Dataset):\n",
        "\n",
        "\n",
        "    def __init__(self, irradiance_file, sequence_length=20, forecast_horizon=4):\n",
        "        self.sequence_length = sequence_length\n",
        "        self.forecast_horizon = forecast_horizon\n",
        "\n",
        "\n",
        "        if irradiance_file.endswith('.csv'):\n",
        "            df = pd.read_csv(irradiance_file)\n",
        "            self.data = df.iloc[:, 1].values.astype(np.float32)\n",
        "        else:\n",
        "            self.data = np.loadtxt(irradiance_file, delimiter=',')[:, 1].astype(np.float32)\n",
        "\n",
        "\n",
        "        self.valid_indices = list(range(len(self.data) - sequence_length - forecast_horizon + 1))\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.valid_indices)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        start_idx = self.valid_indices[idx]\n",
        "\n",
        "\n",
        "        x = torch.tensor(\n",
        "            self.data[start_idx:start_idx + self.sequence_length],\n",
        "            dtype=torch.float32\n",
        "        ).unsqueeze(-1)\n",
        "\n",
        "\n",
        "        y = torch.tensor(\n",
        "            self.data[start_idx + self.sequence_length: start_idx + self.sequence_length + self.forecast_horizon],\n",
        "            dtype=torch.float32\n",
        "        )\n",
        "\n",
        "        return x, y\n",
        "\n",
        "\n",
        "class GSIDataset(SolarIrradianceDataset):\n",
        "\n",
        "\n",
        "    def __init__(self, image_dir, gsi_file):\n",
        "        super().__init__(image_dir, gsi_file)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_tensor, irradiance = super().__getitem__(idx)\n",
        "        return img_tensor, irradiance\n",
        "\n",
        "\n",
        "class GSITimeSeriesDataset(SolarTimeSeriesDataset):\n",
        "\n",
        "\n",
        "    def __init__(self, gsi_values, sequence_length=10):\n",
        "        self.sequence_length = sequence_length\n",
        "        self.data = gsi_values.astype(np.float32)\n",
        "        self.valid_indices = list(range(len(self.data) - sequence_length))\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        start_idx = self.valid_indices[idx]\n",
        "        x = torch.tensor(\n",
        "            self.data[start_idx:start_idx + self.sequence_length],\n",
        "            dtype=torch.float32\n",
        "        ).unsqueeze(-1)\n",
        "        y = torch.tensor(self.data[start_idx + self.sequence_length], dtype=torch.float32)\n",
        "        return x, y\n",
        "\n",
        "\n",
        "def get_multi_day_sequence_dataset(image_dirs, irradiance_files, sequence_length, forecast_horizon):\n",
        "    image_paths = []\n",
        "    irradiance_values = []\n",
        "\n",
        "    for img_dir, irr_file in zip(image_dirs, irradiance_files):\n",
        "\n",
        "        if irr_file.endswith('.csv'):\n",
        "            df = pd.read_csv(irr_file)\n",
        "            values = df.iloc[:, 1].values.astype(np.float32)\n",
        "        else:\n",
        "            values = np.loadtxt(irr_file, delimiter=',')[:, 1].astype(np.float32)\n",
        "\n",
        "        files = sorted([f for f in os.listdir(img_dir) if f.endswith(('.png', '.jpg', '.jpeg'))])\n",
        "        files = files[:len(values)]\n",
        "\n",
        "        image_paths.extend([os.path.join(img_dir, f) for f in files])\n",
        "        irradiance_values.extend(values[:len(files)])\n",
        "\n",
        "    return SolarSequenceDataset(image_paths, irradiance_values, sequence_length, forecast_horizon)\n",
        "\n",
        "\n",
        "class HybridTrainer:\n",
        "\n",
        "\n",
        "    def __init__(self, pretrained_cnn_path=None, config=None):\n",
        "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "        print(f\"Using device: {self.device}\")\n",
        "\n",
        "\n",
        "        self.config = {\n",
        "            'sequence_length': 20,\n",
        "            'forecast_horizon': 4,\n",
        "            'learning_rate': 1e-4,\n",
        "            'batch_size': 16,\n",
        "            'num_epochs': 30,\n",
        "            'lstm_hidden_size': 128,\n",
        "            'feature_dim': 512,\n",
        "            'weight_decay': 1e-4,\n",
        "            'scheduler_patience': 8,\n",
        "            'early_stopping_patience': 12,\n",
        "            'freeze_cnn': True,\n",
        "            'save_dir': 'models',\n",
        "            'log_dir': 'logs'\n",
        "        }\n",
        "\n",
        "        if config:\n",
        "            self.config.update(config)\n",
        "\n",
        "\n",
        "        os.makedirs(self.config['save_dir'], exist_ok=True)\n",
        "        os.makedirs(self.config['log_dir'], exist_ok=True)\n",
        "\n",
        "\n",
        "        cnn_model = None\n",
        "        if pretrained_cnn_path:\n",
        "            print(f\"Loading pretrained CNN from {pretrained_cnn_path}\")\n",
        "            cnn_model = SolarCNNWithFeatureExtraction()\n",
        "            checkpoint = torch.load(pretrained_cnn_cnn_model.state_dict(), map_location=self.device)\n",
        "            cnn_model.load_state_dict(checkpoint['model_state_dict'])\n",
        "\n",
        "        self.model = HybridCNNLSTM(\n",
        "            cnn_model=cnn_model,\n",
        "            feature_dim=self.config['feature_dim'],\n",
        "            sequence_length=self.config['sequence_length'],\n",
        "            lstm_hidden_size=self.config['lstm_hidden_size'],\n",
        "            forecast_horizon=self.config['forecast_horizon']\n",
        "        ).to(self.device)\n",
        "\n",
        "\n",
        "        self.model.set_cnn_trainable(not self.config['freeze_cnn'])\n",
        "\n",
        "\n",
        "        if self.config['freeze_cnn']:\n",
        "\n",
        "            lstm_params = list(self.model.lstm.parameters())\n",
        "            print(f\"Training LSTM only ({sum(p.numel() for p in lstm_params):,} parameters)\")\n",
        "        else:\n",
        "\n",
        "            lstm_params = self.model.parameters()\n",
        "            print(f\"Training full hybrid model ({sum(p.numel() for p in self.model.parameters()):,} parameters)\")\n",
        "\n",
        "        self.optimizer = optim.Adam(\n",
        "            lstm_params,\n",
        "            lr=self.config['learning_rate'],\n",
        "            weight_decay=self.config['weight_decay']\n",
        "        )\n",
        "\n",
        "        self.scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
        "        self.optimizer,\n",
        "        mode='min',\n",
        "        patience=self.config['scheduler_patience'],\n",
        "        factor=0.5\n",
        "        )\n",
        "\n",
        "\n",
        "        self.mse_loss = nn.MSELoss()\n",
        "        self.mae_loss = nn.L1Loss()\n",
        "\n",
        "\n",
        "        self.train_losses = []\n",
        "        self.val_losses = []\n",
        "        self.best_val_loss = float('inf')\n",
        "        self.patience_counter = 0\n",
        "\n",
        "    def train_epoch(self, train_loader):\n",
        "\n",
        "        self.model.train()\n",
        "        total_nowcast_loss = 0.0\n",
        "        total_forecast_loss = 0.0\n",
        "        total_loss = 0.0\n",
        "        num_batches = 0\n",
        "\n",
        "        with tqdm(train_loader, desc=\"Training Hybrid\") as pbar:\n",
        "            for batch_idx, (image_sequences, historical_irradiance, future_irradiance) in enumerate(pbar):\n",
        "                image_sequences = image_sequences.to(self.device)\n",
        "                historical_irradiance = historical_irradiance.to(self.device)\n",
        "                future_irradiance = future_irradiance.to(self.device)\n",
        "\n",
        "                self.optimizer.zero_grad()\n",
        "\n",
        "\n",
        "                nowcasts, forecasts = self.model(image_sequences)\n",
        "\n",
        "\n",
        "                nowcast_loss = self.mse_loss(nowcasts.squeeze(-1), historical_irradiance.squeeze(-1))\n",
        "                forecast_loss = self.mse_loss(forecasts, future_irradiance)\n",
        "\n",
        "\n",
        "                total_batch_loss = 0.3 * nowcast_loss + 0.7 * forecast_loss\n",
        "\n",
        "                total_batch_loss.backward()\n",
        "\n",
        "\n",
        "                torch.nn.utils.clip_grad_norm_(self.model.parameters(), max_norm=1.0)\n",
        "\n",
        "                self.optimizer.step()\n",
        "\n",
        "                total_nowcast_loss += nowcast_loss.item()\n",
        "                total_forecast_loss += forecast_loss.item()\n",
        "                total_loss += total_batch_loss.item()\n",
        "                num_batches += 1\n",
        "\n",
        "\n",
        "                pbar.set_postfix({\n",
        "                    'Nowcast': f'{nowcast_loss.item():.4f}',\n",
        "                    'Forecast': f'{forecast_loss.item():.4f}',\n",
        "                    'Total': f'{total_batch_loss.item():.4f}'\n",
        "                })\n",
        "\n",
        "        return (total_nowcast_loss / num_batches,\n",
        "                total_forecast_loss / num_batches,\n",
        "                total_loss / num_batches)\n",
        "\n",
        "    def validate_epoch(self, val_loader):\n",
        "\n",
        "        self.model.eval()\n",
        "        total_nowcast_loss = 0.0\n",
        "        total_forecast_loss = 0.0\n",
        "        all_nowcast_pred = []\n",
        "        all_nowcast_target = []\n",
        "        all_forecast_pred = []\n",
        "        all_forecast_target = []\n",
        "\n",
        "        with torch.no_grad():\n",
        "            with tqdm(val_loader, desc=\"Validation\") as pbar:\n",
        "                for image_sequences, historical_irradiance, future_irradiance in pbar:\n",
        "                    image_sequences = image_sequences.to(self.device)\n",
        "                    historical_irradiance = historical_irradiance.to(self.device)\n",
        "                    future_irradiance = future_irradiance.to(self.device)\n",
        "\n",
        "                    nowcasts, forecasts = self.model(image_sequences)\n",
        "\n",
        "                    nowcast_loss = self.mse_loss(nowcasts.squeeze(-1), historical_irradiance.squeeze(-1))\n",
        "                    forecast_loss = self.mse_loss(forecasts, future_irradiance)\n",
        "\n",
        "                    total_nowcast_loss += nowcast_loss.item()\n",
        "                    total_forecast_loss += forecast_loss.item()\n",
        "\n",
        "\n",
        "                    all_nowcast_pred.append(nowcasts.squeeze(-1).cpu().numpy())\n",
        "                    all_nowcast_target.append(historical_irradiance.squeeze(-1).cpu().numpy())\n",
        "                    all_forecast_pred.append(forecasts.cpu().numpy())\n",
        "                    all_forecast_target.append(future_irradiance.cpu().numpy())\n",
        "\n",
        "                    pbar.set_postfix({\n",
        "                        'Nowcast': f'{nowcast_loss.item():.4f}',\n",
        "                        'Forecast': f'{forecast_loss.item():.4f}'\n",
        "                    })\n",
        "\n",
        "        avg_nowcast_loss = total_nowcast_loss / len(val_loader)\n",
        "        avg_forecast_loss = total_forecast_loss / len(val_loader)\n",
        "\n",
        "\n",
        "        nowcast_pred = np.concatenate(all_nowcast_pred, axis=0)\n",
        "        nowcast_target = np.concatenate(all_nowcast_target, axis=0)\n",
        "        forecast_pred = np.concatenate(all_forecast_pred, axis=0)\n",
        "        forecast_target = np.concatenate(all_forecast_target, axis=0)\n",
        "\n",
        "\n",
        "        nowcast_rmse = np.sqrt(mean_squared_error(nowcast_target.flatten(), nowcast_pred.flatten()))\n",
        "\n",
        "\n",
        "        forecast_rmse = np.sqrt(mean_squared_error(forecast_target.flatten(), forecast_pred.flatten()))\n",
        "\n",
        "\n",
        "        forecast_rmse_per_step = []\n",
        "        for step in range(self.config['forecast_horizon']):\n",
        "            step_rmse = np.sqrt(mean_squared_error(forecast_target[:, step], forecast_pred[:, step]))\n",
        "            forecast_rmse_per_step.append(step_rmse)\n",
        "\n",
        "        return (avg_nowcast_loss, avg_forecast_loss, nowcast_rmse, forecast_rmse, forecast_rmse_per_step)\n",
        "\n",
        "    def train(self, train_loader, val_loader=None):\n",
        "\n",
        "        print(f\"Starting hybrid CNN-LSTM training for {self.config['num_epochs']} epochs...\")\n",
        "        print(f\"CNN frozen: {self.config['freeze_cnn']}\")\n",
        "\n",
        "        for epoch in range(self.config['num_epochs']):\n",
        "            print(f\"\\nEpoch {epoch+1}/{self.config['num_epochs']}\")\n",
        "\n",
        "\n",
        "            train_nowcast_loss, train_forecast_loss, train_total_loss = self.train_epoch(train_loader)\n",
        "            self.train_losses.append(train_total_loss)\n",
        "\n",
        "            print(f\"Train - Nowcast: {train_nowcast_loss:.4f}, Forecast: {train_forecast_loss:.4f}, Total: {train_total_loss:.4f}\")\n",
        "\n",
        "\n",
        "            if val_loader is not None:\n",
        "                (val_nowcast_loss, val_forecast_loss, nowcast_rmse, forecast_rmse, forecast_rmse_per_step) = self.validate_epoch(val_loader)\n",
        "\n",
        "                val_total_loss = 0.3 * val_nowcast_loss + 0.7 * val_forecast_loss\n",
        "                self.val_losses.append(val_total_loss)\n",
        "\n",
        "                print(f\"Val - Nowcast RMSE: {nowcast_rmse:.2f} W/m², Forecast RMSE: {forecast_rmse:.2f} W/m²\")\n",
        "                print(f\"Forecast RMSE per step: {[f'{r:.2f}' for r in forecast_rmse_per_step]}\")\n",
        "\n",
        "\n",
        "                self.scheduler.step(val_total_loss)\n",
        "\n",
        "\n",
        "                if val_total_loss < self.best_val_loss:\n",
        "                    self.best_val_loss = val_total_loss\n",
        "                    self.patience_counter = 0\n",
        "\n",
        "\n",
        "                    torch.save({\n",
        "                        'epoch': epoch,\n",
        "                        'model_state_dict': self.model.state_dict(),\n",
        "                        'optimizer_state_dict': self.optimizer.state_dict(),\n",
        "                        'val_loss': val_total_loss,\n",
        "                        'nowcast_rmse': nowcast_rmse,\n",
        "                        'forecast_rmse': forecast_rmse,\n",
        "                        'config': self.config\n",
        "                    }, os.path.join(self.config['save_dir'], 'best_hybrid_model.pth'))\n",
        "\n",
        "                    print(f\"New best model saved! Forecast RMSE: {forecast_rmse:.2f} W/m²\")\n",
        "                else:\n",
        "                    self.patience_counter += 1\n",
        "\n",
        "                if self.patience_counter >= self.config['early_stopping_patience']:\n",
        "                    print(f\"Early stopping triggered after {epoch+1} epochs\")\n",
        "                    break\n",
        "\n",
        "\n",
        "        torch.save({\n",
        "            'epoch': epoch,\n",
        "            'model_state_dict': self.model.state_dict(),\n",
        "            'optimizer_state_dict': self.optimizer.state_dict(),\n",
        "            'train_losses': self.train_losses,\n",
        "            'val_losses': self.val_losses\n",
        "        }, os.path.join(self.config['save_dir'], 'final_hybrid_cnn_with_features_model.pth'))\n",
        "\n",
        "\n",
        "        history = {\n",
        "            'train_losses': self.train_losses,\n",
        "            'val_losses': self.val_losses,\n",
        "            'config': self.config\n",
        "        }\n",
        "\n",
        "        with open(os.path.join(self.config['log_dir'], 'hybrid_training_history.json'), 'w') as f:\n",
        "            json.dump(history, f, indent=2)\n",
        "\n",
        "        print(\"Hybrid CNN-LSTM training completed!\")\n",
        "        return self.train_losses, self.val_losses\n",
        "\n",
        "\n",
        "def train_hybrid_model():\n",
        "\n",
        "\n",
        "    config = {\n",
        "        'sequence_length': 20,\n",
        "        'forecast_horizon': 4,\n",
        "        'learning_rate': 1e-4,\n",
        "        'batch_size': 128,\n",
        "        'num_epochs': 50,\n",
        "        'freeze_cnn': True,\n",
        "\n",
        "        'image_dirs': [\n",
        "            '/content/drive/MyDrive/data/processed/2019_01_15',\n",
        "            '/content/drive/MyDrive/data/processed/2019_01_16',\n",
        "            '/content/drive/MyDrive/data/processed/2019_01_17',\n",
        "            '/content/drive/MyDrive/data/processed/2019_01_18'\n",
        "\n",
        "\n",
        "        ],\n",
        "        'irradiance_files': [\n",
        "            '/content/drive/MyDrive/GIRASOL_DATASET/2019_01_15/pyranometer/2019_01_15.csv',\n",
        "            '/content/drive/MyDrive/GIRASOL_DATASET/2019_01_16/pyranometer/2019_01_16.csv',\n",
        "            '/content/drive/MyDrive/GIRASOL_DATASET/2019_01_17/pyranometer/2019_01_17.csv',\n",
        "            '/content/drive/MyDrive/GIRASOL_DATASET/2019_01_18/pyranometer/2019_01_18.csv'\n",
        "        ],\n",
        "        'pretrained_cnn_path': '/content/drive/MyDrive/models(with_feature_cnn)/best_cnn_with_features_model.pth'\n",
        "    }\n",
        "\n",
        "\n",
        "    print(\"Loading multi-day sequence dataset...\")\n",
        "    dataset = get_multi_day_sequence_dataset(\n",
        "        image_dirs=config['image_dirs'],\n",
        "        irradiance_files=config['irradiance_files'],\n",
        "        sequence_length=config['sequence_length'],\n",
        "        forecast_horizon=config['forecast_horizon']\n",
        "    )\n",
        "\n",
        "\n",
        "    train_size = int(0.8 * len(dataset))\n",
        "    val_size = len(dataset) - train_size\n",
        "\n",
        "    train_dataset, val_dataset = torch.utils.data.random_split(\n",
        "        dataset, [train_size, val_size]\n",
        "    )\n",
        "\n",
        "\n",
        "    train_loader = DataLoader(\n",
        "        train_dataset,\n",
        "        batch_size=config['batch_size'],\n",
        "        shuffle=True,\n",
        "        num_workers=2\n",
        "    )\n",
        "\n",
        "    val_loader = DataLoader(\n",
        "        val_dataset,\n",
        "        batch_size=config['batch_size'],\n",
        "        shuffle=False,\n",
        "        num_workers=2\n",
        "    )\n",
        "\n",
        "    print(f\"Train samples: {len(train_dataset)}, Val samples: {len(val_dataset)}\")\n",
        "\n",
        "\n",
        "    trainer = HybridTrainer(\n",
        "        pretrained_cnn_path=config.get('pretrained_cnn_path'),\n",
        "        config=config\n",
        "    )\n",
        "\n",
        "\n",
        "    train_losses, val_losses = trainer.train(train_loader, val_loader)\n",
        "\n",
        "    print(\"Hybrid CNN-LSTM training completed!\")\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    train_hybrid_model()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bVRMj1AUf9yX",
        "outputId": "fcd1581a-8840-484b-d907-9257e15235b9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading multi-day sequence dataset...\n",
            "Train samples: 5381, Val samples: 1346\n",
            "Using device: cpu\n",
            "Loading pretrained CNN from /content/drive/MyDrive/models(with_feature_cnn)/best_cnn_with_features_model.pth\n",
            "Training LSTM only (570,820 parameters)\n",
            "Starting hybrid CNN-LSTM training for 50 epochs...\n",
            "CNN frozen: True\n",
            "\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining Hybrid:   0%|          | 0/43 [00:00<?, ?it/s]"
          ]
        }
      ]
    }
  ]
}